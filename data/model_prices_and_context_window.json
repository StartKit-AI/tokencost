{
  "lastUpdated": 1726676736180,
  "models": {
    "gpt-4": {
      "maxTokens": 4096,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00003,
      "outputCostPerToken": 0.00006,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "openai"
    },
    "gpt-4o": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000005,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "gpt-4o-mini": {
      "maxTokens": 16384,
      "maxInputTokens": 128000,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "gpt-4o-mini-2024-07-18": {
      "maxTokens": 16384,
      "maxInputTokens": 128000,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "o1-mini": {
      "maxTokens": 65536,
      "maxInputTokens": 128000,
      "maxOutputTokens": 65536,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000012,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "o1-mini-2024-09-12": {
      "maxTokens": 65536,
      "maxInputTokens": 128000,
      "maxOutputTokens": 65536,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000012,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "o1-preview": {
      "maxTokens": 32768,
      "maxInputTokens": 128000,
      "maxOutputTokens": 32768,
      "inputCostPerToken": 0.000015,
      "outputCostPerToken": 0.00006,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "o1-preview-2024-09-12": {
      "maxTokens": 32768,
      "maxInputTokens": 128000,
      "maxOutputTokens": 32768,
      "inputCostPerToken": 0.000015,
      "outputCostPerToken": 0.00006,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "chatgpt-4o-latest": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000005,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "gpt-4o-2024-05-13": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000005,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "gpt-4o-2024-08-06": {
      "maxTokens": 16384,
      "maxInputTokens": 128000,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 0.0000025,
      "outputCostPerToken": 0.00001,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "gpt-4-turbo-preview": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "openai"
    },
    "gpt-4-0314": {
      "maxTokens": 4096,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00003,
      "outputCostPerToken": 0.00006,
      "mode": "chat",
      "provider": "openai"
    },
    "gpt-4-0613": {
      "maxTokens": 4096,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00003,
      "outputCostPerToken": 0.00006,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "openai"
    },
    "gpt-4-32k": {
      "maxTokens": 4096,
      "maxInputTokens": 32768,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00006,
      "outputCostPerToken": 0.00012,
      "mode": "chat",
      "provider": "openai"
    },
    "gpt-4-32k-0314": {
      "maxTokens": 4096,
      "maxInputTokens": 32768,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00006,
      "outputCostPerToken": 0.00012,
      "mode": "chat",
      "provider": "openai"
    },
    "gpt-4-32k-0613": {
      "maxTokens": 4096,
      "maxInputTokens": 32768,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00006,
      "outputCostPerToken": 0.00012,
      "mode": "chat",
      "provider": "openai"
    },
    "gpt-4-turbo": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "gpt-4-turbo-2024-04-09": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "gpt-4-1106-preview": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "openai"
    },
    "gpt-4-0125-preview": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "openai"
    },
    "gpt-4-vision-preview": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "mode": "chat",
      "supportsVision": true,
      "provider": "openai"
    },
    "gpt-4-1106-vision-preview": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "mode": "chat",
      "supportsVision": true,
      "provider": "openai"
    },
    "gpt-3.5-turbo": {
      "maxTokens": 4097,
      "maxInputTokens": 16385,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.0000015,
      "outputCostPerToken": 0.000002,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "openai"
    },
    "gpt-3.5-turbo-0301": {
      "maxTokens": 4097,
      "maxInputTokens": 4097,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.0000015,
      "outputCostPerToken": 0.000002,
      "mode": "chat",
      "provider": "openai"
    },
    "gpt-3.5-turbo-0613": {
      "maxTokens": 4097,
      "maxInputTokens": 4097,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.0000015,
      "outputCostPerToken": 0.000002,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "openai"
    },
    "gpt-3.5-turbo-1106": {
      "maxTokens": 16385,
      "maxInputTokens": 16385,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000002,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "openai"
    },
    "gpt-3.5-turbo-0125": {
      "maxTokens": 16385,
      "maxInputTokens": 16385,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 0.0000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "openai"
    },
    "gpt-3.5-turbo-16k": {
      "maxTokens": 16385,
      "maxInputTokens": 16385,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000004,
      "mode": "chat",
      "provider": "openai"
    },
    "gpt-3.5-turbo-16k-0613": {
      "maxTokens": 16385,
      "maxInputTokens": 16385,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000004,
      "mode": "chat",
      "provider": "openai"
    },
    "ft:gpt-3.5-turbo": {
      "maxTokens": 4096,
      "maxInputTokens": 16385,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000006,
      "mode": "chat",
      "provider": "openai"
    },
    "ft:gpt-3.5-turbo-0125": {
      "maxTokens": 4096,
      "maxInputTokens": 16385,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000006,
      "mode": "chat",
      "provider": "openai"
    },
    "ft:gpt-3.5-turbo-1106": {
      "maxTokens": 4096,
      "maxInputTokens": 16385,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000006,
      "mode": "chat",
      "provider": "openai"
    },
    "ft:gpt-3.5-turbo-0613": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000006,
      "mode": "chat",
      "provider": "openai"
    },
    "ft:gpt-4-0613": {
      "maxTokens": 4096,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00003,
      "outputCostPerToken": 0.00006,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "OpenAI needs to add pricing for this ft model, will be updated when added by OpenAI. Defaulting to base model pricing",
      "provider": "openai"
    },
    "ft:gpt-4o-2024-08-06": {
      "maxTokens": 16384,
      "maxInputTokens": 128000,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 0.00000375,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "ft:gpt-4o-mini-2024-07-18": {
      "maxTokens": 16384,
      "maxInputTokens": 128000,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 3e-7,
      "outputCostPerToken": 0.0000012,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "ft:davinci-002": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000002,
      "outputCostPerToken": 0.000002,
      "mode": "completion",
      "provider": "openai"
    },
    "ft:babbage-002": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 4e-7,
      "outputCostPerToken": 4e-7,
      "mode": "completion",
      "provider": "openai"
    },
    "text-embedding-3-large": {
      "maxTokens": 8191,
      "maxInputTokens": 8191,
      "outputVectorSize": 3072,
      "inputCostPerToken": 1.3e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "openai"
    },
    "text-embedding-3-small": {
      "maxTokens": 8191,
      "maxInputTokens": 8191,
      "outputVectorSize": 1536,
      "inputCostPerToken": 2e-8,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "openai"
    },
    "text-embedding-ada-002": {
      "maxTokens": 8191,
      "maxInputTokens": 8191,
      "outputVectorSize": 1536,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "openai"
    },
    "text-embedding-ada-002-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 8191,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "openai"
    },
    "text-moderation-stable": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 0,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "moderations",
      "provider": "openai"
    },
    "text-moderation-007": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 0,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "moderations",
      "provider": "openai"
    },
    "text-moderation-latest": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 0,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "moderations",
      "provider": "openai"
    },
    "256-x-256/dall-e-2": {
      "mode": "image_generation",
      "inputCostPerPixel": 2.4414e-7,
      "outputCostPerPixel": 0,
      "provider": "openai"
    },
    "512-x-512/dall-e-2": {
      "mode": "image_generation",
      "inputCostPerPixel": 6.86e-8,
      "outputCostPerPixel": 0,
      "provider": "openai"
    },
    "1024-x-1024/dall-e-2": {
      "mode": "image_generation",
      "inputCostPerPixel": 1.9e-8,
      "outputCostPerPixel": 0,
      "provider": "openai"
    },
    "hd/1024-x-1792/dall-e-3": {
      "mode": "image_generation",
      "inputCostPerPixel": 6.539e-8,
      "outputCostPerPixel": 0,
      "provider": "openai"
    },
    "hd/1792-x-1024/dall-e-3": {
      "mode": "image_generation",
      "inputCostPerPixel": 6.539e-8,
      "outputCostPerPixel": 0,
      "provider": "openai"
    },
    "hd/1024-x-1024/dall-e-3": {
      "mode": "image_generation",
      "inputCostPerPixel": 7.629e-8,
      "outputCostPerPixel": 0,
      "provider": "openai"
    },
    "standard/1024-x-1792/dall-e-3": {
      "mode": "image_generation",
      "inputCostPerPixel": 4.359e-8,
      "outputCostPerPixel": 0,
      "provider": "openai"
    },
    "standard/1792-x-1024/dall-e-3": {
      "mode": "image_generation",
      "inputCostPerPixel": 4.359e-8,
      "outputCostPerPixel": 0,
      "provider": "openai"
    },
    "standard/1024-x-1024/dall-e-3": {
      "mode": "image_generation",
      "inputCostPerPixel": 3.81469e-8,
      "outputCostPerPixel": 0,
      "provider": "openai"
    },
    "whisper-1": {
      "mode": "audio_transcription",
      "inputCostPerSecond": 0,
      "outputCostPerSecond": 0.0001,
      "provider": "openai"
    },
    "tts-1": {
      "mode": "audio_speech",
      "inputCostPerCharacter": 0.000015,
      "provider": "openai"
    },
    "tts-1-hd": {
      "mode": "audio_speech",
      "inputCostPerCharacter": 0.00003,
      "provider": "openai"
    },
    "azure/tts-1": {
      "mode": "audio_speech",
      "inputCostPerCharacter": 0.000015,
      "provider": "azure"
    },
    "azure/tts-1-hd": {
      "mode": "audio_speech",
      "inputCostPerCharacter": 0.00003,
      "provider": "azure"
    },
    "azure/whisper-1": {
      "mode": "audio_transcription",
      "inputCostPerSecond": 0,
      "outputCostPerSecond": 0.0001,
      "provider": "azure"
    },
    "azure/gpt-4o": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000005,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "azure"
    },
    "azure/gpt-4o-2024-08-06": {
      "maxTokens": 16384,
      "maxInputTokens": 128000,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 0.00000275,
      "outputCostPerToken": 0.000011,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "azure"
    },
    "azure/global-standard/gpt-4o-2024-08-06": {
      "maxTokens": 16384,
      "maxInputTokens": 128000,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 0.0000025,
      "outputCostPerToken": 0.00001,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "azure"
    },
    "azure/global-standard/gpt-4o-mini": {
      "maxTokens": 16384,
      "maxInputTokens": 128000,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "azure"
    },
    "azure/gpt-4o-mini": {
      "maxTokens": 16384,
      "maxInputTokens": 128000,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 1.65e-7,
      "outputCostPerToken": 6.6e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "azure"
    },
    "azure/gpt-4-turbo-2024-04-09": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "azure"
    },
    "azure/gpt-4-0125-preview": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "azure"
    },
    "azure/gpt-4-1106-preview": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "azure"
    },
    "azure/gpt-4-0613": {
      "maxTokens": 4096,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00003,
      "outputCostPerToken": 0.00006,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "azure"
    },
    "azure/gpt-4-32k-0613": {
      "maxTokens": 4096,
      "maxInputTokens": 32768,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00006,
      "outputCostPerToken": 0.00012,
      "mode": "chat",
      "provider": "azure"
    },
    "azure/gpt-4-32k": {
      "maxTokens": 4096,
      "maxInputTokens": 32768,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00006,
      "outputCostPerToken": 0.00012,
      "mode": "chat",
      "provider": "azure"
    },
    "azure/gpt-4": {
      "maxTokens": 4096,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00003,
      "outputCostPerToken": 0.00006,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "azure"
    },
    "azure/gpt-4-turbo": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "azure"
    },
    "azure/gpt-4-turbo-vision-preview": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "mode": "chat",
      "supportsVision": true,
      "provider": "azure"
    },
    "azure/gpt-35-turbo-16k-0613": {
      "maxTokens": 4096,
      "maxInputTokens": 16385,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000004,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "azure"
    },
    "azure/gpt-35-turbo-1106": {
      "maxTokens": 4096,
      "maxInputTokens": 16384,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000002,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "azure"
    },
    "azure/gpt-35-turbo-0125": {
      "maxTokens": 4096,
      "maxInputTokens": 16384,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 0.0000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "azure"
    },
    "azure/gpt-35-turbo-16k": {
      "maxTokens": 4096,
      "maxInputTokens": 16385,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000004,
      "mode": "chat",
      "provider": "azure"
    },
    "azure/gpt-35-turbo": {
      "maxTokens": 4096,
      "maxInputTokens": 4097,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 0.0000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "azure"
    },
    "azure/gpt-3.5-turbo-instruct-0914": {
      "maxTokens": 4097,
      "maxInputTokens": 4097,
      "inputCostPerToken": 0.0000015,
      "outputCostPerToken": 0.000002,
      "mode": "completion",
      "provider": "openai"
    },
    "azure/gpt-35-turbo-instruct": {
      "maxTokens": 4097,
      "maxInputTokens": 4097,
      "inputCostPerToken": 0.0000015,
      "outputCostPerToken": 0.000002,
      "mode": "completion",
      "provider": "openai"
    },
    "azure/mistral-large-latest": {
      "maxTokens": 32000,
      "maxInputTokens": 32000,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "azure"
    },
    "azure/mistral-large-2402": {
      "maxTokens": 32000,
      "maxInputTokens": 32000,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "azure"
    },
    "azure/command-r-plus": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "azure"
    },
    "azure/ada": {
      "maxTokens": 8191,
      "maxInputTokens": 8191,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "azure"
    },
    "azure/text-embedding-ada-002": {
      "maxTokens": 8191,
      "maxInputTokens": 8191,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "azure"
    },
    "azure/text-embedding-3-large": {
      "maxTokens": 8191,
      "maxInputTokens": 8191,
      "inputCostPerToken": 1.3e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "azure"
    },
    "azure/text-embedding-3-small": {
      "maxTokens": 8191,
      "maxInputTokens": 8191,
      "inputCostPerToken": 2e-8,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "azure"
    },
    "azure/standard/1024-x-1024/dall-e-3": {
      "inputCostPerPixel": 3.81469e-8,
      "outputCostPerToken": 0,
      "mode": "image_generation",
      "provider": "azure"
    },
    "azure/hd/1024-x-1024/dall-e-3": {
      "inputCostPerPixel": 7.629e-8,
      "outputCostPerToken": 0,
      "mode": "image_generation",
      "provider": "azure"
    },
    "azure/standard/1024-x-1792/dall-e-3": {
      "inputCostPerPixel": 4.359e-8,
      "outputCostPerToken": 0,
      "mode": "image_generation",
      "provider": "azure"
    },
    "azure/standard/1792-x-1024/dall-e-3": {
      "inputCostPerPixel": 4.359e-8,
      "outputCostPerToken": 0,
      "mode": "image_generation",
      "provider": "azure"
    },
    "azure/hd/1024-x-1792/dall-e-3": {
      "inputCostPerPixel": 6.539e-8,
      "outputCostPerToken": 0,
      "mode": "image_generation",
      "provider": "azure"
    },
    "azure/hd/1792-x-1024/dall-e-3": {
      "inputCostPerPixel": 6.539e-8,
      "outputCostPerToken": 0,
      "mode": "image_generation",
      "provider": "azure"
    },
    "azure/standard/1024-x-1024/dall-e-2": {
      "inputCostPerPixel": 0,
      "outputCostPerToken": 0,
      "mode": "image_generation",
      "provider": "azure"
    },
    "azure_ai/jamba-instruct": {
      "maxTokens": 4096,
      "maxInputTokens": 70000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 7e-7,
      "mode": "chat",
      "provider": "azure_ai"
    },
    "azure_ai/mistral-large": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000004,
      "outputCostPerToken": 0.000012,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "azure_ai"
    },
    "azure_ai/mistral-small": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000003,
      "supportsFunctionCalling": true,
      "mode": "chat",
      "provider": "azure_ai"
    },
    "azure_ai/Meta-Llama-3-70B-Instruct": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.0000011,
      "outputCostPerToken": 3.7e-7,
      "mode": "chat",
      "provider": "azure_ai"
    },
    "azure_ai/Meta-Llama-31-8B-Instruct": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 3e-7,
      "outputCostPerToken": 6.1e-7,
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice",
      "provider": "azure_ai"
    },
    "azure_ai/Meta-Llama-31-70B-Instruct": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 0.00000268,
      "outputCostPerToken": 0.00000354,
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice",
      "provider": "azure_ai"
    },
    "azure_ai/Meta-Llama-31-405B-Instruct": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 0.00000533,
      "outputCostPerToken": 0.000016,
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice",
      "provider": "azure_ai"
    },
    "babbage-002": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 4e-7,
      "outputCostPerToken": 4e-7,
      "mode": "completion",
      "provider": "openai"
    },
    "davinci-002": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000002,
      "outputCostPerToken": 0.000002,
      "mode": "completion",
      "provider": "openai"
    },
    "gpt-3.5-turbo-instruct": {
      "maxTokens": 4096,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.0000015,
      "outputCostPerToken": 0.000002,
      "mode": "completion",
      "provider": "openai"
    },
    "gpt-3.5-turbo-instruct-0914": {
      "maxTokens": 4097,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4097,
      "inputCostPerToken": 0.0000015,
      "outputCostPerToken": 0.000002,
      "mode": "completion",
      "provider": "openai"
    },
    "claude-instant-1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.00000163,
      "outputCostPerToken": 0.00000551,
      "mode": "chat",
      "provider": "anthropic"
    },
    "mistral/mistral-tiny": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 2.5e-7,
      "mode": "chat",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/mistral-small": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000003,
      "supportsFunctionCalling": true,
      "mode": "chat",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/mistral-small-latest": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000003,
      "supportsFunctionCalling": true,
      "mode": "chat",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/mistral-medium": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.0000027,
      "outputCostPerToken": 0.0000081,
      "mode": "chat",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/mistral-medium-latest": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.0000027,
      "outputCostPerToken": 0.0000081,
      "mode": "chat",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/mistral-medium-2312": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.0000027,
      "outputCostPerToken": 0.0000081,
      "mode": "chat",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/mistral-large-latest": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000009,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/mistral-large-2402": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000004,
      "outputCostPerToken": 0.000012,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/mistral-large-2407": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000009,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/open-mistral-7b": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 2.5e-7,
      "mode": "chat",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/open-mixtral-8x7b": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 7e-7,
      "outputCostPerToken": 7e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/open-mixtral-8x22b": {
      "maxTokens": 8191,
      "maxInputTokens": 64000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000002,
      "outputCostPerToken": 0.000006,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/codestral-latest": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000003,
      "mode": "chat",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/codestral-2405": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000003,
      "mode": "chat",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/open-mistral-nemo": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 3e-7,
      "outputCostPerToken": 3e-7,
      "mode": "chat",
      "source": "https://mistral.ai/technology/",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/open-mistral-nemo-2407": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 3e-7,
      "outputCostPerToken": 3e-7,
      "mode": "chat",
      "source": "https://mistral.ai/technology/",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/open-codestral-mamba": {
      "maxTokens": 256000,
      "maxInputTokens": 256000,
      "maxOutputTokens": 256000,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 2.5e-7,
      "mode": "chat",
      "source": "https://mistral.ai/technology/",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/codestral-mamba-latest": {
      "maxTokens": 256000,
      "maxInputTokens": 256000,
      "maxOutputTokens": 256000,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 2.5e-7,
      "mode": "chat",
      "source": "https://mistral.ai/technology/",
      "supportsAssistantPrefill": true,
      "provider": "mistral"
    },
    "mistral/mistral-embed": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "inputCostPerToken": 1e-7,
      "mode": "embedding",
      "provider": "mistral"
    },
    "deepseek-chat": {
      "maxTokens": 4096,
      "maxInputTokens": 32000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.4e-7,
      "inputCostPerTokenCacheHit": 1.4e-8,
      "outputCostPerToken": 2.8e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsAssistantPrefill": true,
      "supportsToolChoice": true,
      "provider": "deepseek"
    },
    "codestral/codestral-latest": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "source": "https://docs.mistral.ai/capabilities/code_generation/",
      "supportsAssistantPrefill": true,
      "provider": "codestral"
    },
    "codestral/codestral-2405": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "source": "https://docs.mistral.ai/capabilities/code_generation/",
      "supportsAssistantPrefill": true,
      "provider": "codestral"
    },
    "text-completion-codestral/codestral-latest": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "source": "https://docs.mistral.ai/capabilities/code_generation/",
      "provider": "text-completion-codestral"
    },
    "text-completion-codestral/codestral-2405": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "source": "https://docs.mistral.ai/capabilities/code_generation/",
      "provider": "text-completion-codestral"
    },
    "deepseek-coder": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.4e-7,
      "inputCostPerTokenCacheHit": 1.4e-8,
      "outputCostPerToken": 2.8e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsAssistantPrefill": true,
      "supportsToolChoice": true,
      "provider": "deepseek"
    },
    "groq/llama2-70b-4096": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 7e-7,
      "outputCostPerToken": 8e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "groq"
    },
    "groq/llama3-8b-8192": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 5e-8,
      "outputCostPerToken": 8e-8,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "groq"
    },
    "groq/llama3-70b-8192": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 5.9e-7,
      "outputCostPerToken": 7.9e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "groq"
    },
    "groq/llama-3.1-8b-instant": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 5.9e-7,
      "outputCostPerToken": 7.9e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "groq"
    },
    "groq/llama-3.1-70b-versatile": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 5.9e-7,
      "outputCostPerToken": 7.9e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "groq"
    },
    "groq/llama-3.1-405b-reasoning": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 5.9e-7,
      "outputCostPerToken": 7.9e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "groq"
    },
    "groq/mixtral-8x7b-32768": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 32768,
      "inputCostPerToken": 2.4e-7,
      "outputCostPerToken": 2.4e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "groq"
    },
    "groq/gemma-7b-it": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 7e-8,
      "outputCostPerToken": 7e-8,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "groq"
    },
    "groq/llama3-groq-70b-8192-tool-use-preview": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 8.9e-7,
      "outputCostPerToken": 8.9e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "groq"
    },
    "groq/llama3-groq-8b-8192-tool-use-preview": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 1.9e-7,
      "outputCostPerToken": 1.9e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "groq"
    },
    "cerebras/llama3.1-8b": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 1e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "cerebras"
    },
    "cerebras/llama3.1-70b": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 6e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "cerebras"
    },
    "friendliai/mixtral-8x7b-instruct-v0-1": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 32768,
      "inputCostPerToken": 4e-7,
      "outputCostPerToken": 4e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "friendliai"
    },
    "friendliai/meta-llama-3-8b-instruct": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 1e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "friendliai"
    },
    "friendliai/meta-llama-3-70b-instruct": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 8e-7,
      "outputCostPerToken": 8e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "friendliai"
    },
    "claude-instant-1.2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 1.63e-7,
      "outputCostPerToken": 5.51e-7,
      "mode": "chat",
      "provider": "anthropic"
    },
    "claude-2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "anthropic"
    },
    "claude-2.1": {
      "maxTokens": 8191,
      "maxInputTokens": 200000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "anthropic"
    },
    "claude-3-haiku-20240307": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 0.00000125,
      "cacheCreationInputTokenCost": 3e-7,
      "cacheReadInputTokenCost": 3e-8,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "toolUseSystemPromptTokens": 264,
      "supportsAssistantPrefill": true,
      "provider": "anthropic"
    },
    "claude-3-opus-20240229": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000015,
      "outputCostPerToken": 0.000075,
      "cacheCreationInputTokenCost": 0.00001875,
      "cacheReadInputTokenCost": 0.0000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "toolUseSystemPromptTokens": 395,
      "supportsAssistantPrefill": true,
      "provider": "anthropic"
    },
    "claude-3-sonnet-20240229": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "toolUseSystemPromptTokens": 159,
      "supportsAssistantPrefill": true,
      "provider": "anthropic"
    },
    "claude-3-5-sonnet-20240620": {
      "maxTokens": 8192,
      "maxInputTokens": 200000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "cacheCreationInputTokenCost": 0.00000375,
      "cacheReadInputTokenCost": 3e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "toolUseSystemPromptTokens": 159,
      "supportsAssistantPrefill": true,
      "provider": "anthropic"
    },
    "text-bison": {
      "maxTokens": 2048,
      "maxInputTokens": 8192,
      "maxOutputTokens": 2048,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-text-models"
    },
    "text-bison@001": {
      "maxTokens": 1024,
      "maxInputTokens": 8192,
      "maxOutputTokens": 1024,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-text-models"
    },
    "text-bison@002": {
      "maxTokens": 1024,
      "maxInputTokens": 8192,
      "maxOutputTokens": 1024,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-text-models"
    },
    "text-bison32k": {
      "maxTokens": 1024,
      "maxInputTokens": 8192,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-text-models"
    },
    "text-bison32k@002": {
      "maxTokens": 1024,
      "maxInputTokens": 8192,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-text-models"
    },
    "text-unicorn": {
      "maxTokens": 1024,
      "maxInputTokens": 8192,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.000028,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-text-models"
    },
    "text-unicorn@001": {
      "maxTokens": 1024,
      "maxInputTokens": 8192,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.000028,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-text-models"
    },
    "chat-bison": {
      "maxTokens": 4096,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-chat-models"
    },
    "chat-bison@001": {
      "maxTokens": 4096,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-chat-models"
    },
    "chat-bison@002": {
      "maxTokens": 4096,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-chat-models"
    },
    "chat-bison-32k": {
      "maxTokens": 8192,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-chat-models"
    },
    "chat-bison-32k@002": {
      "maxTokens": 8192,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-chat-models"
    },
    "code-bison": {
      "maxTokens": 1024,
      "maxInputTokens": 6144,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "code-bison@001": {
      "maxTokens": 1024,
      "maxInputTokens": 6144,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "code-bison@002": {
      "maxTokens": 1024,
      "maxInputTokens": 6144,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "code-bison32k": {
      "maxTokens": 1024,
      "maxInputTokens": 6144,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "code-bison-32k@002": {
      "maxTokens": 1024,
      "maxInputTokens": 6144,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "code-gecko@001": {
      "maxTokens": 64,
      "maxInputTokens": 2048,
      "maxOutputTokens": 64,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "code-gecko@002": {
      "maxTokens": 64,
      "maxInputTokens": 2048,
      "maxOutputTokens": 64,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "code-gecko": {
      "maxTokens": 64,
      "maxInputTokens": 2048,
      "maxOutputTokens": 64,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "code-gecko-latest": {
      "maxTokens": 64,
      "maxInputTokens": 2048,
      "maxOutputTokens": 64,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-text-models"
    },
    "codechat-bison@latest": {
      "maxTokens": 1024,
      "maxInputTokens": 6144,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-chat-models"
    },
    "codechat-bison": {
      "maxTokens": 1024,
      "maxInputTokens": 6144,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-chat-models"
    },
    "codechat-bison@001": {
      "maxTokens": 1024,
      "maxInputTokens": 6144,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-chat-models"
    },
    "codechat-bison@002": {
      "maxTokens": 1024,
      "maxInputTokens": 6144,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-chat-models"
    },
    "codechat-bison-32k": {
      "maxTokens": 8192,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-chat-models"
    },
    "codechat-bison-32k@002": {
      "maxTokens": 8192,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "inputCostPerCharacter": 2.5e-7,
      "outputCostPerCharacter": 5e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-code-chat-models"
    },
    "gemini-pro": {
      "maxTokens": 8192,
      "maxInputTokens": 32760,
      "maxOutputTokens": 8192,
      "inputCostPerImage": 0.0025,
      "inputCostPerVideoPerSecond": 0.002,
      "inputCostPerToken": 5e-7,
      "inputCostPerCharacter": 1.25e-7,
      "outputCostPerToken": 0.0000015,
      "outputCostPerCharacter": 3.75e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.0-pro": {
      "maxTokens": 8192,
      "maxInputTokens": 32760,
      "maxOutputTokens": 8192,
      "inputCostPerImage": 0.0025,
      "inputCostPerVideoPerSecond": 0.002,
      "inputCostPerToken": 5e-7,
      "inputCostPerCharacter": 1.25e-7,
      "outputCostPerToken": 0.0000015,
      "outputCostPerCharacter": 3.75e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.0-pro-001": {
      "maxTokens": 8192,
      "maxInputTokens": 32760,
      "maxOutputTokens": 8192,
      "inputCostPerImage": 0.0025,
      "inputCostPerVideoPerSecond": 0.002,
      "inputCostPerToken": 5e-7,
      "inputCostPerCharacter": 1.25e-7,
      "outputCostPerToken": 0.0000015,
      "outputCostPerCharacter": 3.75e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.0-ultra": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 2048,
      "inputCostPerImage": 0.0025,
      "inputCostPerVideoPerSecond": 0.002,
      "inputCostPerToken": 5e-7,
      "inputCostPerCharacter": 1.25e-7,
      "outputCostPerToken": 0.0000015,
      "outputCostPerCharacter": 3.75e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.0-ultra-001": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 2048,
      "inputCostPerImage": 0.0025,
      "inputCostPerVideoPerSecond": 0.002,
      "inputCostPerToken": 5e-7,
      "inputCostPerCharacter": 1.25e-7,
      "outputCostPerToken": 0.0000015,
      "outputCostPerCharacter": 3.75e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.0-pro-002": {
      "maxTokens": 8192,
      "maxInputTokens": 32760,
      "maxOutputTokens": 8192,
      "inputCostPerImage": 0.0025,
      "inputCostPerVideoPerSecond": 0.002,
      "inputCostPerToken": 5e-7,
      "inputCostPerCharacter": 1.25e-7,
      "outputCostPerToken": 0.0000015,
      "outputCostPerCharacter": 3.75e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.5-pro": {
      "maxTokens": 8192,
      "maxInputTokens": 2097152,
      "maxOutputTokens": 8192,
      "inputCostPerImage": 0.001315,
      "inputCostPerAudioPerSecond": 0.000125,
      "inputCostPerVideoPerSecond": 0.001315,
      "inputCostPerToken": 0.000005,
      "inputCostPerCharacter": 0.00000125,
      "inputCostPerTokenAbove128kTokens": 0.00001,
      "inputCostPerCharacterAbove128kTokens": 0.0000025,
      "outputCostPerToken": 0.000015,
      "outputCostPerCharacter": 0.00000375,
      "outputCostPerTokenAbove128kTokens": 0.00003,
      "outputCostPerCharacterAbove128kTokens": 0.0000075,
      "outputCostPerImage": 0.00263,
      "outputCostPerVideoPerSecond": 0.00263,
      "outputCostPerAudioPerSecond": 0.00025,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsToolChoice": true,
      "supportsResponseSchema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.5-pro-001": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "inputCostPerImage": 0.001315,
      "inputCostPerAudioPerSecond": 0.000125,
      "inputCostPerVideoPerSecond": 0.001315,
      "inputCostPerToken": 0.000005,
      "inputCostPerCharacter": 0.00000125,
      "inputCostPerTokenAbove128kTokens": 0.00001,
      "inputCostPerCharacterAbove128kTokens": 0.0000025,
      "outputCostPerToken": 0.000015,
      "outputCostPerCharacter": 0.00000375,
      "outputCostPerTokenAbove128kTokens": 0.00003,
      "outputCostPerCharacterAbove128kTokens": 0.0000075,
      "outputCostPerImage": 0.00263,
      "outputCostPerVideoPerSecond": 0.00263,
      "outputCostPerAudioPerSecond": 0.00025,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsToolChoice": true,
      "supportsResponseSchema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.5-pro-preview-0514": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "inputCostPerImage": 0.001315,
      "inputCostPerAudioPerSecond": 0.000125,
      "inputCostPerVideoPerSecond": 0.001315,
      "inputCostPerToken": 0.000005,
      "inputCostPerCharacter": 0.00000125,
      "inputCostPerTokenAbove128kTokens": 0.00001,
      "inputCostPerCharacterAbove128kTokens": 0.0000025,
      "outputCostPerToken": 0.000015,
      "outputCostPerCharacter": 0.00000375,
      "outputCostPerTokenAbove128kTokens": 0.00003,
      "outputCostPerCharacterAbove128kTokens": 0.0000075,
      "outputCostPerImage": 0.00263,
      "outputCostPerVideoPerSecond": 0.00263,
      "outputCostPerAudioPerSecond": 0.00025,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsToolChoice": true,
      "supportsResponseSchema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.5-pro-preview-0215": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "inputCostPerImage": 0.001315,
      "inputCostPerAudioPerSecond": 0.000125,
      "inputCostPerVideoPerSecond": 0.001315,
      "inputCostPerToken": 0.000005,
      "inputCostPerCharacter": 0.00000125,
      "inputCostPerTokenAbove128kTokens": 0.00001,
      "inputCostPerCharacterAbove128kTokens": 0.0000025,
      "outputCostPerToken": 0.000015,
      "outputCostPerCharacter": 0.00000375,
      "outputCostPerTokenAbove128kTokens": 0.00003,
      "outputCostPerCharacterAbove128kTokens": 0.0000075,
      "outputCostPerImage": 0.00263,
      "outputCostPerVideoPerSecond": 0.00263,
      "outputCostPerAudioPerSecond": 0.00025,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsToolChoice": true,
      "supportsResponseSchema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.5-pro-preview-0409": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "inputCostPerImage": 0.001315,
      "inputCostPerAudioPerSecond": 0.000125,
      "inputCostPerVideoPerSecond": 0.001315,
      "inputCostPerToken": 0.000005,
      "inputCostPerCharacter": 0.00000125,
      "inputCostPerTokenAbove128kTokens": 0.00001,
      "inputCostPerCharacterAbove128kTokens": 0.0000025,
      "outputCostPerToken": 0.000015,
      "outputCostPerCharacter": 0.00000375,
      "outputCostPerTokenAbove128kTokens": 0.00003,
      "outputCostPerCharacterAbove128kTokens": 0.0000075,
      "outputCostPerImage": 0.00263,
      "outputCostPerVideoPerSecond": 0.00263,
      "outputCostPerAudioPerSecond": 0.00025,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsToolChoice": true,
      "supportsResponseSchema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.5-flash": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "maxImagesPerPrompt": 3000,
      "maxVideosPerPrompt": 10,
      "maxVideoLength": 1,
      "maxAudioLengthHours": 8.4,
      "maxAudioPerPrompt": 1,
      "maxPdfSizeMb": 30,
      "inputCostPerImage": 0.0001315,
      "inputCostPerVideoPerSecond": 0.0001315,
      "inputCostPerAudioPerSecond": 0.000125,
      "inputCostPerToken": 5e-7,
      "inputCostPerCharacter": 1.25e-7,
      "inputCostPerTokenAbove128kTokens": 0.000001,
      "inputCostPerCharacterAbove128kTokens": 2.5e-7,
      "outputCostPerToken": 0.0000015,
      "outputCostPerCharacter": 3.75e-7,
      "outputCostPerTokenAbove128kTokens": 0.000003,
      "outputCostPerCharacterAbove128kTokens": 7.5e-7,
      "outputCostPerImage": 0.000263,
      "outputCostPerVideoPerSecond": 0.000263,
      "outputCostPerAudioPerSecond": 0.00025,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsResponseSchema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.5-flash-exp-0827": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "maxImagesPerPrompt": 3000,
      "maxVideosPerPrompt": 10,
      "maxVideoLength": 1,
      "maxAudioLengthHours": 8.4,
      "maxAudioPerPrompt": 1,
      "maxPdfSizeMb": 30,
      "inputCostPerImage": 0.0001315,
      "inputCostPerVideoPerSecond": 0.0001315,
      "inputCostPerAudioPerSecond": 0.000125,
      "inputCostPerToken": 5e-7,
      "inputCostPerCharacter": 1.25e-7,
      "inputCostPerTokenAbove128kTokens": 0.000001,
      "inputCostPerCharacterAbove128kTokens": 2.5e-7,
      "outputCostPerToken": 0.0000015,
      "outputCostPerCharacter": 3.75e-7,
      "outputCostPerTokenAbove128kTokens": 0.000003,
      "outputCostPerCharacterAbove128kTokens": 7.5e-7,
      "outputCostPerImage": 0.000263,
      "outputCostPerVideoPerSecond": 0.000263,
      "outputCostPerAudioPerSecond": 0.00025,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsResponseSchema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.5-flash-001": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "maxImagesPerPrompt": 3000,
      "maxVideosPerPrompt": 10,
      "maxVideoLength": 1,
      "maxAudioLengthHours": 8.4,
      "maxAudioPerPrompt": 1,
      "maxPdfSizeMb": 30,
      "inputCostPerImage": 0.0001315,
      "inputCostPerVideoPerSecond": 0.0001315,
      "inputCostPerAudioPerSecond": 0.000125,
      "inputCostPerToken": 5e-7,
      "inputCostPerCharacter": 1.25e-7,
      "inputCostPerTokenAbove128kTokens": 0.000001,
      "inputCostPerCharacterAbove128kTokens": 2.5e-7,
      "outputCostPerToken": 0.0000015,
      "outputCostPerCharacter": 3.75e-7,
      "outputCostPerTokenAbove128kTokens": 0.000003,
      "outputCostPerCharacterAbove128kTokens": 7.5e-7,
      "outputCostPerImage": 0.000263,
      "outputCostPerVideoPerSecond": 0.000263,
      "outputCostPerAudioPerSecond": 0.00025,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsResponseSchema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-1.5-flash-preview-0514": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "maxImagesPerPrompt": 3000,
      "maxVideosPerPrompt": 10,
      "maxVideoLength": 1,
      "maxAudioLengthHours": 8.4,
      "maxAudioPerPrompt": 1,
      "maxPdfSizeMb": 30,
      "inputCostPerImage": 0.0001315,
      "inputCostPerVideoPerSecond": 0.0001315,
      "inputCostPerAudioPerSecond": 0.000125,
      "inputCostPerToken": 5e-7,
      "inputCostPerCharacter": 1.25e-7,
      "inputCostPerTokenAbove128kTokens": 0.000001,
      "inputCostPerCharacterAbove128kTokens": 2.5e-7,
      "outputCostPerToken": 0.0000015,
      "outputCostPerCharacter": 3.75e-7,
      "outputCostPerTokenAbove128kTokens": 0.000003,
      "outputCostPerCharacterAbove128kTokens": 7.5e-7,
      "outputCostPerImage": 0.000263,
      "outputCostPerVideoPerSecond": 0.000263,
      "outputCostPerAudioPerSecond": 0.00025,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "gemini-pro-experimental": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "inputCostPerCharacter": 0,
      "outputCostPerCharacter": 0,
      "mode": "chat",
      "supportsFunctionCalling": false,
      "supportsToolChoice": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental",
      "provider": "vertex_ai-language-models"
    },
    "gemini-pro-flash": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "inputCostPerCharacter": 0,
      "outputCostPerCharacter": 0,
      "mode": "chat",
      "supportsFunctionCalling": false,
      "supportsToolChoice": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental",
      "provider": "vertex_ai-language-models"
    },
    "gemini-pro-vision": {
      "maxTokens": 2048,
      "maxInputTokens": 16384,
      "maxOutputTokens": 2048,
      "maxImagesPerPrompt": 16,
      "maxVideosPerPrompt": 1,
      "maxVideoLength": 2,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 5e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-vision-models"
    },
    "gemini-1.0-pro-vision": {
      "maxTokens": 2048,
      "maxInputTokens": 16384,
      "maxOutputTokens": 2048,
      "maxImagesPerPrompt": 16,
      "maxVideosPerPrompt": 1,
      "maxVideoLength": 2,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 5e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-vision-models"
    },
    "gemini-1.0-pro-vision-001": {
      "maxTokens": 2048,
      "maxInputTokens": 16384,
      "maxOutputTokens": 2048,
      "maxImagesPerPrompt": 16,
      "maxVideosPerPrompt": 1,
      "maxVideoLength": 2,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 5e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-vision-models"
    },
    "medlm-medium": {
      "maxTokens": 8192,
      "maxInputTokens": 32768,
      "maxOutputTokens": 8192,
      "inputCostPerCharacter": 5e-7,
      "outputCostPerCharacter": 0.000001,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "medlm-large": {
      "maxTokens": 1024,
      "maxInputTokens": 8192,
      "maxOutputTokens": 1024,
      "inputCostPerCharacter": 0.000005,
      "outputCostPerCharacter": 0.000015,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-language-models"
    },
    "vertex_ai/claude-3-sonnet@20240229": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsAssistantPrefill": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "vertex_ai/claude-3-5-sonnet@20240620": {
      "maxTokens": 8192,
      "maxInputTokens": 200000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsAssistantPrefill": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "vertex_ai/claude-3-haiku@20240307": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 0.00000125,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsAssistantPrefill": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "vertex_ai/claude-3-opus@20240229": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000015,
      "outputCostPerToken": 0.000075,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsAssistantPrefill": true,
      "provider": "vertex_ai-anthropic_models"
    },
    "vertex_ai/meta/llama3-405b-instruct-maas": {
      "maxTokens": 32000,
      "maxInputTokens": 32000,
      "maxOutputTokens": 32000,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
      "provider": "vertex_ai-llama_models"
    },
    "vertex_ai/mistral-large@latest": {
      "maxTokens": 8191,
      "maxInputTokens": 128000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000009,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "vertex_ai-mistral_models"
    },
    "vertex_ai/mistral-large@2407": {
      "maxTokens": 8191,
      "maxInputTokens": 128000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000009,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "vertex_ai-mistral_models"
    },
    "vertex_ai/mistral-nemo@latest": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "vertex_ai-mistral_models"
    },
    "vertex_ai/jamba-1.5-mini@001": {
      "maxTokens": 256000,
      "maxInputTokens": 256000,
      "maxOutputTokens": 256000,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 4e-7,
      "mode": "chat",
      "provider": "vertex_ai-ai21_models"
    },
    "vertex_ai/jamba-1.5-large@001": {
      "maxTokens": 256000,
      "maxInputTokens": 256000,
      "maxOutputTokens": 256000,
      "inputCostPerToken": 0.000002,
      "outputCostPerToken": 0.000008,
      "mode": "chat",
      "provider": "vertex_ai-ai21_models"
    },
    "vertex_ai/jamba-1.5": {
      "maxTokens": 256000,
      "maxInputTokens": 256000,
      "maxOutputTokens": 256000,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 4e-7,
      "mode": "chat",
      "provider": "vertex_ai-ai21_models"
    },
    "vertex_ai/jamba-1.5-mini": {
      "maxTokens": 256000,
      "maxInputTokens": 256000,
      "maxOutputTokens": 256000,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 4e-7,
      "mode": "chat",
      "provider": "vertex_ai-ai21_models"
    },
    "vertex_ai/jamba-1.5-large": {
      "maxTokens": 256000,
      "maxInputTokens": 256000,
      "maxOutputTokens": 256000,
      "inputCostPerToken": 0.000002,
      "outputCostPerToken": 0.000008,
      "mode": "chat",
      "provider": "vertex_ai-ai21_models"
    },
    "vertex_ai/mistral-nemo@2407": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "vertex_ai-mistral_models"
    },
    "vertex_ai/codestral@latest": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "vertex_ai-mistral_models"
    },
    "vertex_ai/codestral@2405": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "vertex_ai-mistral_models"
    },
    "vertex_ai/imagegeneration@006": {
      "costPerImage": 0.02,
      "mode": "image_generation",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "provider": "vertex_ai-image-models"
    },
    "vertex_ai/imagen-3.0-generate-001": {
      "costPerImage": 0.04,
      "mode": "image_generation",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "provider": "vertex_ai-image-models"
    },
    "vertex_ai/imagen-3.0-fast-generate-001": {
      "costPerImage": 0.02,
      "mode": "image_generation",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "provider": "vertex_ai-image-models"
    },
    "text-embedding-004": {
      "maxTokens": 3072,
      "maxInputTokens": 3072,
      "outputVectorSize": 768,
      "inputCostPerToken": 6.25e-9,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
      "provider": "vertex_ai-embedding-models"
    },
    "text-multilingual-embedding-002": {
      "maxTokens": 2048,
      "maxInputTokens": 2048,
      "outputVectorSize": 768,
      "inputCostPerToken": 6.25e-9,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
      "provider": "vertex_ai-embedding-models"
    },
    "textembedding-gecko": {
      "maxTokens": 3072,
      "maxInputTokens": 3072,
      "outputVectorSize": 768,
      "inputCostPerToken": 6.25e-9,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-embedding-models"
    },
    "textembedding-gecko-multilingual": {
      "maxTokens": 3072,
      "maxInputTokens": 3072,
      "outputVectorSize": 768,
      "inputCostPerToken": 6.25e-9,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-embedding-models"
    },
    "textembedding-gecko-multilingual@001": {
      "maxTokens": 3072,
      "maxInputTokens": 3072,
      "outputVectorSize": 768,
      "inputCostPerToken": 6.25e-9,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-embedding-models"
    },
    "textembedding-gecko@001": {
      "maxTokens": 3072,
      "maxInputTokens": 3072,
      "outputVectorSize": 768,
      "inputCostPerToken": 6.25e-9,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-embedding-models"
    },
    "textembedding-gecko@003": {
      "maxTokens": 3072,
      "maxInputTokens": 3072,
      "outputVectorSize": 768,
      "inputCostPerToken": 6.25e-9,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-embedding-models"
    },
    "text-embedding-preview-0409": {
      "maxTokens": 3072,
      "maxInputTokens": 3072,
      "outputVectorSize": 768,
      "inputCostPerToken": 6.25e-9,
      "inputCostPerTokenBatchRequests": 5e-9,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "provider": "vertex_ai-embedding-models"
    },
    "text-multilingual-embedding-preview-0409": {
      "maxTokens": 3072,
      "maxInputTokens": 3072,
      "outputVectorSize": 768,
      "inputCostPerToken": 6.25e-9,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "vertex_ai-embedding-models"
    },
    "palm/chat-bison": {
      "maxTokens": 4096,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "palm"
    },
    "palm/chat-bison-001": {
      "maxTokens": 4096,
      "maxInputTokens": 8192,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "palm"
    },
    "palm/text-bison": {
      "maxTokens": 1024,
      "maxInputTokens": 8192,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "palm"
    },
    "palm/text-bison-001": {
      "maxTokens": 1024,
      "maxInputTokens": 8192,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "palm"
    },
    "palm/text-bison-safety-off": {
      "maxTokens": 1024,
      "maxInputTokens": 8192,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "palm"
    },
    "palm/text-bison-safety-recitation-off": {
      "maxTokens": 1024,
      "maxInputTokens": 8192,
      "maxOutputTokens": 1024,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 1.25e-7,
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "palm"
    },
    "gemini/gemini-1.5-flash-001": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "maxImagesPerPrompt": 3000,
      "maxVideosPerPrompt": 10,
      "maxVideoLength": 1,
      "maxAudioLengthHours": 8.4,
      "maxAudioPerPrompt": 1,
      "maxPdfSizeMb": 30,
      "inputCostPerToken": 7.5e-8,
      "inputCostPerTokenAbove128kTokens": 1.5e-7,
      "outputCostPerToken": 3e-7,
      "outputCostPerTokenAbove128kTokens": 6e-7,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsResponseSchema": true,
      "source": "https://ai.google.dev/pricing",
      "provider": "gemini"
    },
    "gemini/gemini-1.5-flash": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "maxImagesPerPrompt": 3000,
      "maxVideosPerPrompt": 10,
      "maxVideoLength": 1,
      "maxAudioLengthHours": 8.4,
      "maxAudioPerPrompt": 1,
      "maxPdfSizeMb": 30,
      "inputCostPerToken": 7.5e-8,
      "inputCostPerTokenAbove128kTokens": 1.5e-7,
      "outputCostPerToken": 3e-7,
      "outputCostPerTokenAbove128kTokens": 6e-7,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsResponseSchema": true,
      "source": "https://ai.google.dev/pricing",
      "provider": "gemini"
    },
    "gemini/gemini-1.5-flash-latest": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "maxImagesPerPrompt": 3000,
      "maxVideosPerPrompt": 10,
      "maxVideoLength": 1,
      "maxAudioLengthHours": 8.4,
      "maxAudioPerPrompt": 1,
      "maxPdfSizeMb": 30,
      "inputCostPerToken": 7.5e-8,
      "inputCostPerTokenAbove128kTokens": 1.5e-7,
      "outputCostPerToken": 3e-7,
      "outputCostPerTokenAbove128kTokens": 6e-7,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsResponseSchema": true,
      "source": "https://ai.google.dev/pricing",
      "provider": "gemini"
    },
    "gemini/gemini-1.5-flash-exp-0827": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "maxImagesPerPrompt": 3000,
      "maxVideosPerPrompt": 10,
      "maxVideoLength": 1,
      "maxAudioLengthHours": 8.4,
      "maxAudioPerPrompt": 1,
      "maxPdfSizeMb": 30,
      "inputCostPerToken": 0,
      "inputCostPerTokenAbove128kTokens": 0,
      "outputCostPerToken": 0,
      "outputCostPerTokenAbove128kTokens": 0,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsResponseSchema": true,
      "source": "https://ai.google.dev/pricing",
      "provider": "gemini"
    },
    "gemini/gemini-1.5-flash-8b-exp-0827": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "maxImagesPerPrompt": 3000,
      "maxVideosPerPrompt": 10,
      "maxVideoLength": 1,
      "maxAudioLengthHours": 8.4,
      "maxAudioPerPrompt": 1,
      "maxPdfSizeMb": 30,
      "inputCostPerToken": 0,
      "inputCostPerTokenAbove128kTokens": 0,
      "outputCostPerToken": 0,
      "outputCostPerTokenAbove128kTokens": 0,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "source": "https://ai.google.dev/pricing",
      "provider": "gemini"
    },
    "gemini/gemini-pro": {
      "maxTokens": 8192,
      "maxInputTokens": 32760,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 3.5e-7,
      "inputCostPerTokenAbove128kTokens": 7e-7,
      "outputCostPerToken": 0.00000105,
      "outputCostPerTokenAbove128kTokens": 0.0000021,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "gemini"
    },
    "gemini/gemini-1.5-pro": {
      "maxTokens": 8192,
      "maxInputTokens": 2097152,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.0000035,
      "inputCostPerTokenAbove128kTokens": 0.000007,
      "outputCostPerToken": 0.0000105,
      "outputCostPerTokenAbove128kTokens": 0.000021,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsToolChoice": true,
      "supportsResponseSchema": true,
      "source": "https://ai.google.dev/pricing",
      "provider": "gemini"
    },
    "gemini/gemini-1.5-pro-exp-0801": {
      "maxTokens": 8192,
      "maxInputTokens": 2097152,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.0000035,
      "inputCostPerTokenAbove128kTokens": 0.000007,
      "outputCostPerToken": 0.0000105,
      "outputCostPerTokenAbove128kTokens": 0.000021,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsToolChoice": true,
      "supportsResponseSchema": true,
      "source": "https://ai.google.dev/pricing",
      "provider": "gemini"
    },
    "gemini/gemini-1.5-pro-exp-0827": {
      "maxTokens": 8192,
      "maxInputTokens": 2097152,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "inputCostPerTokenAbove128kTokens": 0,
      "outputCostPerToken": 0,
      "outputCostPerTokenAbove128kTokens": 0,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsToolChoice": true,
      "supportsResponseSchema": true,
      "source": "https://ai.google.dev/pricing",
      "provider": "gemini"
    },
    "gemini/gemini-1.5-pro-latest": {
      "maxTokens": 8192,
      "maxInputTokens": 1048576,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.0000035,
      "inputCostPerTokenAbove128kTokens": 0.000007,
      "outputCostPerToken": 0.00000105,
      "outputCostPerTokenAbove128kTokens": 0.000021,
      "mode": "chat",
      "supportsSystemMessages": true,
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "supportsToolChoice": true,
      "supportsResponseSchema": true,
      "source": "https://ai.google.dev/pricing",
      "provider": "gemini"
    },
    "gemini/gemini-pro-vision": {
      "maxTokens": 2048,
      "maxInputTokens": 30720,
      "maxOutputTokens": 2048,
      "inputCostPerToken": 3.5e-7,
      "inputCostPerTokenAbove128kTokens": 7e-7,
      "outputCostPerToken": 0.00000105,
      "outputCostPerTokenAbove128kTokens": 0.0000021,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "gemini"
    },
    "gemini/gemini-gemma-2-27b-it": {
      "maxTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 3.5e-7,
      "outputCostPerToken": 0.00000105,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "gemini"
    },
    "gemini/gemini-gemma-2-9b-it": {
      "maxTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 3.5e-7,
      "outputCostPerToken": 0.00000105,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
      "provider": "gemini"
    },
    "command-r": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "cohere_chat"
    },
    "command-r-08-2024": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "cohere_chat"
    },
    "command-light": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 3e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "provider": "cohere_chat"
    },
    "command-r-plus": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.0000025,
      "outputCostPerToken": 0.00001,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "cohere_chat"
    },
    "command-r-plus-08-2024": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.0000025,
      "outputCostPerToken": 0.00001,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "cohere_chat"
    },
    "command-nightly": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000002,
      "mode": "completion",
      "provider": "cohere"
    },
    "command": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000002,
      "mode": "completion",
      "provider": "cohere"
    },
    "embed-english-v3.0": {
      "maxTokens": 512,
      "maxInputTokens": 512,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "cohere"
    },
    "embed-english-light-v3.0": {
      "maxTokens": 512,
      "maxInputTokens": 512,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "cohere"
    },
    "embed-multilingual-v3.0": {
      "maxTokens": 512,
      "maxInputTokens": 512,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "cohere"
    },
    "embed-english-v2.0": {
      "maxTokens": 512,
      "maxInputTokens": 512,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "cohere"
    },
    "embed-english-light-v2.0": {
      "maxTokens": 512,
      "maxInputTokens": 512,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "cohere"
    },
    "embed-multilingual-v2.0": {
      "maxTokens": 256,
      "maxInputTokens": 256,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "cohere"
    },
    "replicate/meta/llama-2-13b": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 5e-7,
      "mode": "chat",
      "provider": "replicate"
    },
    "replicate/meta/llama-2-13b-chat": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 5e-7,
      "mode": "chat",
      "provider": "replicate"
    },
    "replicate/meta/llama-2-70b": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 6.5e-7,
      "outputCostPerToken": 0.00000275,
      "mode": "chat",
      "provider": "replicate"
    },
    "replicate/meta/llama-2-70b-chat": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 6.5e-7,
      "outputCostPerToken": 0.00000275,
      "mode": "chat",
      "provider": "replicate"
    },
    "replicate/meta/llama-2-7b": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5e-8,
      "outputCostPerToken": 2.5e-7,
      "mode": "chat",
      "provider": "replicate"
    },
    "replicate/meta/llama-2-7b-chat": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5e-8,
      "outputCostPerToken": 2.5e-7,
      "mode": "chat",
      "provider": "replicate"
    },
    "replicate/meta/llama-3-70b": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 6.5e-7,
      "outputCostPerToken": 0.00000275,
      "mode": "chat",
      "provider": "replicate"
    },
    "replicate/meta/llama-3-70b-instruct": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 6.5e-7,
      "outputCostPerToken": 0.00000275,
      "mode": "chat",
      "provider": "replicate"
    },
    "replicate/meta/llama-3-8b": {
      "maxTokens": 8086,
      "maxInputTokens": 8086,
      "maxOutputTokens": 8086,
      "inputCostPerToken": 5e-8,
      "outputCostPerToken": 2.5e-7,
      "mode": "chat",
      "provider": "replicate"
    },
    "replicate/meta/llama-3-8b-instruct": {
      "maxTokens": 8086,
      "maxInputTokens": 8086,
      "maxOutputTokens": 8086,
      "inputCostPerToken": 5e-8,
      "outputCostPerToken": 2.5e-7,
      "mode": "chat",
      "provider": "replicate"
    },
    "replicate/mistralai/mistral-7b-v0.1": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5e-8,
      "outputCostPerToken": 2.5e-7,
      "mode": "chat",
      "provider": "replicate"
    },
    "replicate/mistralai/mistral-7b-instruct-v0.2": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5e-8,
      "outputCostPerToken": 2.5e-7,
      "mode": "chat",
      "provider": "replicate"
    },
    "replicate/mistralai/mixtral-8x7b-instruct-v0.1": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 3e-7,
      "outputCostPerToken": 0.000001,
      "mode": "chat",
      "provider": "replicate"
    },
    "openrouter/deepseek/deepseek-coder": {
      "maxTokens": 4096,
      "maxInputTokens": 32000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.4e-7,
      "outputCostPerToken": 2.8e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/microsoft/wizardlm-2-8x22b:nitro": {
      "maxTokens": 65536,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000001,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/google/gemini-pro-1.5": {
      "maxTokens": 8192,
      "maxInputTokens": 1000000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.0000025,
      "outputCostPerToken": 0.0000075,
      "inputCostPerImage": 0.00265,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "openrouter"
    },
    "openrouter/mistralai/mixtral-8x22b-instruct": {
      "maxTokens": 65536,
      "inputCostPerToken": 6.5e-7,
      "outputCostPerToken": 6.5e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/cohere/command-r-plus": {
      "maxTokens": 128000,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/databricks/dbrx-instruct": {
      "maxTokens": 32768,
      "inputCostPerToken": 6e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/anthropic/claude-3-haiku": {
      "maxTokens": 200000,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 0.00000125,
      "inputCostPerImage": 0.0004,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "openrouter"
    },
    "openrouter/anthropic/claude-3-haiku-20240307": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 0.00000125,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "toolUseSystemPromptTokens": 264,
      "provider": "openrouter"
    },
    "openrouter/anthropic/claude-3.5-sonnet": {
      "maxTokens": 8192,
      "maxInputTokens": 200000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "toolUseSystemPromptTokens": 159,
      "supportsAssistantPrefill": true,
      "provider": "openrouter"
    },
    "openrouter/anthropic/claude-3.5-sonnet:beta": {
      "maxTokens": 8192,
      "maxInputTokens": 200000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "toolUseSystemPromptTokens": 159,
      "provider": "openrouter"
    },
    "openrouter/anthropic/claude-3-sonnet": {
      "maxTokens": 200000,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "inputCostPerImage": 0.0048,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "openrouter"
    },
    "openrouter/mistralai/mistral-large": {
      "maxTokens": 32000,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/cognitivecomputations/dolphin-mixtral-8x7b": {
      "maxTokens": 32769,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 5e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/google/gemini-pro-vision": {
      "maxTokens": 45875,
      "inputCostPerToken": 1.25e-7,
      "outputCostPerToken": 3.75e-7,
      "inputCostPerImage": 0.0025,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "openrouter"
    },
    "openrouter/fireworks/firellava-13b": {
      "maxTokens": 4096,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 2e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/meta-llama/llama-3-8b-instruct:free": {
      "maxTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/meta-llama/llama-3-8b-instruct:extended": {
      "maxTokens": 16384,
      "inputCostPerToken": 2.25e-7,
      "outputCostPerToken": 0.00000225,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/meta-llama/llama-3-70b-instruct:nitro": {
      "maxTokens": 8192,
      "inputCostPerToken": 9e-7,
      "outputCostPerToken": 9e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/meta-llama/llama-3-70b-instruct": {
      "maxTokens": 8192,
      "inputCostPerToken": 5.9e-7,
      "outputCostPerToken": 7.9e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/openai/o1-mini": {
      "maxTokens": 65536,
      "maxInputTokens": 128000,
      "maxOutputTokens": 65536,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000012,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "openrouter/openai/o1-mini-2024-09-12": {
      "maxTokens": 65536,
      "maxInputTokens": 128000,
      "maxOutputTokens": 65536,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000012,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "openrouter/openai/o1-preview": {
      "maxTokens": 32768,
      "maxInputTokens": 128000,
      "maxOutputTokens": 32768,
      "inputCostPerToken": 0.000015,
      "outputCostPerToken": 0.00006,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "openrouter/openai/o1-preview-2024-09-12": {
      "maxTokens": 32768,
      "maxInputTokens": 128000,
      "maxOutputTokens": 32768,
      "inputCostPerToken": 0.000015,
      "outputCostPerToken": 0.00006,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openai"
    },
    "openrouter/openai/gpt-4o": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000005,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openrouter"
    },
    "openrouter/openai/gpt-4o-2024-05-13": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000005,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "supportsVision": true,
      "provider": "openrouter"
    },
    "openrouter/openai/gpt-4-vision-preview": {
      "maxTokens": 130000,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00003,
      "inputCostPerImage": 0.01445,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "openrouter"
    },
    "openrouter/openai/gpt-3.5-turbo": {
      "maxTokens": 4095,
      "inputCostPerToken": 0.0000015,
      "outputCostPerToken": 0.000002,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/openai/gpt-3.5-turbo-16k": {
      "maxTokens": 16383,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000004,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/openai/gpt-4": {
      "maxTokens": 8192,
      "inputCostPerToken": 0.00003,
      "outputCostPerToken": 0.00006,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/anthropic/claude-instant-v1": {
      "maxTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.00000163,
      "outputCostPerToken": 0.00000551,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/anthropic/claude-2": {
      "maxTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.00001102,
      "outputCostPerToken": 0.00003268,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/anthropic/claude-3-opus": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000015,
      "outputCostPerToken": 0.000075,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "toolUseSystemPromptTokens": 395,
      "provider": "openrouter"
    },
    "openrouter/google/palm-2-chat-bison": {
      "maxTokens": 25804,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 5e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/google/palm-2-codechat-bison": {
      "maxTokens": 20070,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 5e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/meta-llama/llama-2-13b-chat": {
      "maxTokens": 4096,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 2e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/meta-llama/llama-2-70b-chat": {
      "maxTokens": 4096,
      "inputCostPerToken": 0.0000015,
      "outputCostPerToken": 0.0000015,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/meta-llama/codellama-34b-instruct": {
      "maxTokens": 8192,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 5e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/nousresearch/nous-hermes-llama2-13b": {
      "maxTokens": 4096,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 2e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/mancer/weaver": {
      "maxTokens": 8000,
      "inputCostPerToken": 0.000005625,
      "outputCostPerToken": 0.000005625,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/gryphe/mythomax-l2-13b": {
      "maxTokens": 8192,
      "inputCostPerToken": 0.000001875,
      "outputCostPerToken": 0.000001875,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/jondurbin/airoboros-l2-70b-2.1": {
      "maxTokens": 4096,
      "inputCostPerToken": 0.000013875,
      "outputCostPerToken": 0.000013875,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/undi95/remm-slerp-l2-13b": {
      "maxTokens": 6144,
      "inputCostPerToken": 0.000001875,
      "outputCostPerToken": 0.000001875,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/pygmalionai/mythalion-13b": {
      "maxTokens": 4096,
      "inputCostPerToken": 0.000001875,
      "outputCostPerToken": 0.000001875,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/mistralai/mistral-7b-instruct": {
      "maxTokens": 8192,
      "inputCostPerToken": 1.3e-7,
      "outputCostPerToken": 1.3e-7,
      "mode": "chat",
      "provider": "openrouter"
    },
    "openrouter/mistralai/mistral-7b-instruct:free": {
      "maxTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "openrouter"
    },
    "j2-ultra": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.000015,
      "outputCostPerToken": 0.000015,
      "mode": "completion",
      "provider": "ai21"
    },
    "jamba-1.5-mini@001": {
      "maxTokens": 256000,
      "maxInputTokens": 256000,
      "maxOutputTokens": 256000,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 4e-7,
      "mode": "chat",
      "provider": "ai21"
    },
    "jamba-1.5-large@001": {
      "maxTokens": 256000,
      "maxInputTokens": 256000,
      "maxOutputTokens": 256000,
      "inputCostPerToken": 0.000002,
      "outputCostPerToken": 0.000008,
      "mode": "chat",
      "provider": "ai21"
    },
    "jamba-1.5": {
      "maxTokens": 256000,
      "maxInputTokens": 256000,
      "maxOutputTokens": 256000,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 4e-7,
      "mode": "chat",
      "provider": "ai21"
    },
    "jamba-1.5-mini": {
      "maxTokens": 256000,
      "maxInputTokens": 256000,
      "maxOutputTokens": 256000,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 4e-7,
      "mode": "chat",
      "provider": "ai21"
    },
    "jamba-1.5-large": {
      "maxTokens": 256000,
      "maxInputTokens": 256000,
      "maxOutputTokens": 256000,
      "inputCostPerToken": 0.000002,
      "outputCostPerToken": 0.000008,
      "mode": "chat",
      "provider": "ai21"
    },
    "j2-mid": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.00001,
      "outputCostPerToken": 0.00001,
      "mode": "completion",
      "provider": "ai21"
    },
    "j2-light": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000003,
      "mode": "completion",
      "provider": "ai21"
    },
    "dolphin": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 5e-7,
      "mode": "completion",
      "provider": "nlp_cloud"
    },
    "chatdolphin": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 5e-7,
      "mode": "chat",
      "provider": "nlp_cloud"
    },
    "luminous-base": {
      "maxTokens": 2048,
      "inputCostPerToken": 0.00003,
      "outputCostPerToken": 0.000033,
      "mode": "completion",
      "provider": "aleph_alpha"
    },
    "luminous-base-control": {
      "maxTokens": 2048,
      "inputCostPerToken": 0.0000375,
      "outputCostPerToken": 0.00004125,
      "mode": "chat",
      "provider": "aleph_alpha"
    },
    "luminous-extended": {
      "maxTokens": 2048,
      "inputCostPerToken": 0.000045,
      "outputCostPerToken": 0.0000495,
      "mode": "completion",
      "provider": "aleph_alpha"
    },
    "luminous-extended-control": {
      "maxTokens": 2048,
      "inputCostPerToken": 0.00005625,
      "outputCostPerToken": 0.000061875,
      "mode": "chat",
      "provider": "aleph_alpha"
    },
    "luminous-supreme": {
      "maxTokens": 2048,
      "inputCostPerToken": 0.000175,
      "outputCostPerToken": 0.0001925,
      "mode": "completion",
      "provider": "aleph_alpha"
    },
    "luminous-supreme-control": {
      "maxTokens": 2048,
      "inputCostPerToken": 0.00021875,
      "outputCostPerToken": 0.000240625,
      "mode": "chat",
      "provider": "aleph_alpha"
    },
    "ai21.j2-mid-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 8191,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.0000125,
      "outputCostPerToken": 0.0000125,
      "mode": "chat",
      "provider": "bedrock"
    },
    "ai21.j2-ultra-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 8191,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.0000188,
      "outputCostPerToken": 0.0000188,
      "mode": "chat",
      "provider": "bedrock"
    },
    "ai21.jamba-instruct-v1:0": {
      "maxTokens": 4096,
      "maxInputTokens": 70000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 7e-7,
      "mode": "chat",
      "supportsSystemMessages": true,
      "provider": "bedrock"
    },
    "amazon.titan-text-lite-v1": {
      "maxTokens": 4000,
      "maxInputTokens": 42000,
      "maxOutputTokens": 4000,
      "inputCostPerToken": 3e-7,
      "outputCostPerToken": 4e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "amazon.titan-text-express-v1": {
      "maxTokens": 8000,
      "maxInputTokens": 42000,
      "maxOutputTokens": 8000,
      "inputCostPerToken": 0.0000013,
      "outputCostPerToken": 0.0000017,
      "mode": "chat",
      "provider": "bedrock"
    },
    "amazon.titan-text-premier-v1:0": {
      "maxTokens": 32000,
      "maxInputTokens": 42000,
      "maxOutputTokens": 32000,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 0.0000015,
      "mode": "chat",
      "provider": "bedrock"
    },
    "amazon.titan-embed-text-v1": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "outputVectorSize": 1536,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "bedrock"
    },
    "amazon.titan-embed-text-v2:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "outputVectorSize": 1024,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "bedrock"
    },
    "mistral.mistral-7b-instruct-v0:2": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 2e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "mistral.mixtral-8x7b-instruct-v0:1": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 4.5e-7,
      "outputCostPerToken": 7e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "mistral.mistral-large-2402-v1:0": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "bedrock"
    },
    "mistral.mistral-large-2407-v1:0": {
      "maxTokens": 8191,
      "maxInputTokens": 128000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000009,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "bedrock"
    },
    "mistral.mistral-small-2402-v1:0": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "bedrock"
    },
    "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 4.5e-7,
      "outputCostPerToken": 7e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 4.5e-7,
      "outputCostPerToken": 7e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 5.9e-7,
      "outputCostPerToken": 9.1e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 2e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 2e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 2.6e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/mistral.mistral-large-2402-v1:0": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/mistral.mistral-large-2402-v1:0": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "bedrock"
    },
    "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0": {
      "maxTokens": 8191,
      "maxInputTokens": 32000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.0000104,
      "outputCostPerToken": 0.0000312,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "bedrock"
    },
    "anthropic.claude-3-sonnet-20240229-v1:0": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "bedrock"
    },
    "anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 200000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "bedrock"
    },
    "anthropic.claude-3-haiku-20240307-v1:0": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 0.00000125,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "bedrock"
    },
    "anthropic.claude-3-opus-20240229-v1:0": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000015,
      "outputCostPerToken": 0.000075,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "bedrock"
    },
    "us.anthropic.claude-3-sonnet-20240229-v1:0": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "bedrock"
    },
    "us.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 200000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "bedrock"
    },
    "us.anthropic.claude-3-haiku-20240307-v1:0": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 0.00000125,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "bedrock"
    },
    "us.anthropic.claude-3-opus-20240229-v1:0": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000015,
      "outputCostPerToken": 0.000075,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "bedrock"
    },
    "eu.anthropic.claude-3-sonnet-20240229-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 200000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "bedrock"
    },
    "eu.anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 200000,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "bedrock"
    },
    "eu.anthropic.claude-3-haiku-20240307-v1:0": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 0.00000125,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "bedrock"
    },
    "eu.anthropic.claude-3-opus-20240229-v1:0": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000015,
      "outputCostPerToken": 0.000075,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsVision": true,
      "provider": "bedrock"
    },
    "anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-northeast-1/anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.0455,
      "outputCostPerSecond": 0.0455,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.02527,
      "outputCostPerSecond": 0.02527,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-central-1/anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.0415,
      "outputCostPerSecond": 0.0415,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.02305,
      "outputCostPerSecond": 0.02305,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.0175,
      "outputCostPerSecond": 0.0175,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.00972,
      "outputCostPerSecond": 0.00972,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.0175,
      "outputCostPerSecond": 0.0175,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.00972,
      "outputCostPerSecond": 0.00972,
      "mode": "chat",
      "provider": "bedrock"
    },
    "anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-northeast-1/anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.0455,
      "outputCostPerSecond": 0.0455,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.02527,
      "outputCostPerSecond": 0.02527,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-central-1/anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.0415,
      "outputCostPerSecond": 0.0415,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.02305,
      "outputCostPerSecond": 0.02305,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.0175,
      "outputCostPerSecond": 0.0175,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.00972,
      "outputCostPerSecond": 0.00972,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.0175,
      "outputCostPerSecond": 0.0175,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.00972,
      "outputCostPerSecond": 0.00972,
      "mode": "chat",
      "provider": "bedrock"
    },
    "anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-northeast-1/anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.0455,
      "outputCostPerSecond": 0.0455,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.02527,
      "outputCostPerSecond": 0.02527,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-central-1/anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.000008,
      "outputCostPerToken": 0.000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.0415,
      "outputCostPerSecond": 0.0415,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.02305,
      "outputCostPerSecond": 0.02305,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.0175,
      "outputCostPerSecond": 0.0175,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.00972,
      "outputCostPerSecond": 0.00972,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.0175,
      "outputCostPerSecond": 0.0175,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.00972,
      "outputCostPerSecond": 0.00972,
      "mode": "chat",
      "provider": "bedrock"
    },
    "anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.00000163,
      "outputCostPerToken": 0.00000551,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 8e-7,
      "outputCostPerToken": 0.0000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.011,
      "outputCostPerSecond": 0.011,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.00611,
      "outputCostPerSecond": 0.00611,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.011,
      "outputCostPerSecond": 0.011,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.00611,
      "outputCostPerSecond": 0.00611,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-2/anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 8e-7,
      "outputCostPerToken": 0.0000024,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-northeast-1/anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.00000223,
      "outputCostPerToken": 0.00000755,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.01475,
      "outputCostPerSecond": 0.01475,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.008194,
      "outputCostPerSecond": 0.008194,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-central-1/anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 0.00000248,
      "outputCostPerToken": 0.00000838,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.01635,
      "outputCostPerSecond": 0.01635,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1": {
      "maxTokens": 8191,
      "maxInputTokens": 100000,
      "maxOutputTokens": 8191,
      "inputCostPerSecond": 0.009083,
      "outputCostPerSecond": 0.009083,
      "mode": "chat",
      "provider": "bedrock"
    },
    "cohere.command-text-v14": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.0000015,
      "outputCostPerToken": 0.000002,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/*/1-month-commitment/cohere.command-text-v14": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerSecond": 0.011,
      "outputCostPerSecond": 0.011,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/*/6-month-commitment/cohere.command-text-v14": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerSecond": 0.0066027,
      "outputCostPerSecond": 0.0066027,
      "mode": "chat",
      "provider": "bedrock"
    },
    "cohere.command-light-text-v14": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 3e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/*/1-month-commitment/cohere.command-light-text-v14": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerSecond": 0.001902,
      "outputCostPerSecond": 0.001902,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/*/6-month-commitment/cohere.command-light-text-v14": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerSecond": 0.0011416,
      "outputCostPerSecond": 0.0011416,
      "mode": "chat",
      "provider": "bedrock"
    },
    "cohere.command-r-plus-v1:0": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000015,
      "mode": "chat",
      "provider": "bedrock"
    },
    "cohere.command-r-v1:0": {
      "maxTokens": 4096,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 0.0000015,
      "mode": "chat",
      "provider": "bedrock"
    },
    "cohere.embed-english-v3": {
      "maxTokens": 512,
      "maxInputTokens": 512,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "bedrock"
    },
    "cohere.embed-multilingual-v3": {
      "maxTokens": 512,
      "maxInputTokens": 512,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "bedrock"
    },
    "meta.llama2-13b-chat-v1": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 7.5e-7,
      "outputCostPerToken": 0.000001,
      "mode": "chat",
      "provider": "bedrock"
    },
    "meta.llama2-70b-chat-v1": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00000195,
      "outputCostPerToken": 0.00000256,
      "mode": "chat",
      "provider": "bedrock"
    },
    "meta.llama3-8b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 3e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/meta.llama3-8b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 3e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-1/meta.llama3-8b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 3e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 3.6e-7,
      "outputCostPerToken": 7.2e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 3.5e-7,
      "outputCostPerToken": 6.9e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 3.2e-7,
      "outputCostPerToken": 6.5e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 3.9e-7,
      "outputCostPerToken": 7.8e-7,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 5e-7,
      "outputCostPerToken": 0.00000101,
      "mode": "chat",
      "provider": "bedrock"
    },
    "meta.llama3-70b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.00000265,
      "outputCostPerToken": 0.0000035,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-east-1/meta.llama3-70b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.00000265,
      "outputCostPerToken": 0.0000035,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/us-west-1/meta.llama3-70b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.00000265,
      "outputCostPerToken": 0.0000035,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.00000318,
      "outputCostPerToken": 0.0000042,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.00000305,
      "outputCostPerToken": 0.00000403,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.00000286,
      "outputCostPerToken": 0.00000378,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.00000345,
      "outputCostPerToken": 0.00000455,
      "mode": "chat",
      "provider": "bedrock"
    },
    "bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.00000445,
      "outputCostPerToken": 0.00000588,
      "mode": "chat",
      "provider": "bedrock"
    },
    "meta.llama3-1-8b-instruct-v1:0": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 2048,
      "inputCostPerToken": 2.2e-7,
      "outputCostPerToken": 2.2e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsToolChoice": false,
      "provider": "bedrock"
    },
    "meta.llama3-1-70b-instruct-v1:0": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 2048,
      "inputCostPerToken": 9.9e-7,
      "outputCostPerToken": 9.9e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsToolChoice": false,
      "provider": "bedrock"
    },
    "meta.llama3-1-405b-instruct-v1:0": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.00000532,
      "outputCostPerToken": 0.000016,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "supportsToolChoice": false,
      "provider": "bedrock"
    },
    "512-x-512/50-steps/stability.stable-diffusion-xl-v0": {
      "maxTokens": 77,
      "maxInputTokens": 77,
      "outputCostPerImage": 0.018,
      "mode": "image_generation",
      "provider": "bedrock"
    },
    "512-x-512/max-steps/stability.stable-diffusion-xl-v0": {
      "maxTokens": 77,
      "maxInputTokens": 77,
      "outputCostPerImage": 0.036,
      "mode": "image_generation",
      "provider": "bedrock"
    },
    "max-x-max/50-steps/stability.stable-diffusion-xl-v0": {
      "maxTokens": 77,
      "maxInputTokens": 77,
      "outputCostPerImage": 0.036,
      "mode": "image_generation",
      "provider": "bedrock"
    },
    "max-x-max/max-steps/stability.stable-diffusion-xl-v0": {
      "maxTokens": 77,
      "maxInputTokens": 77,
      "outputCostPerImage": 0.072,
      "mode": "image_generation",
      "provider": "bedrock"
    },
    "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1": {
      "maxTokens": 77,
      "maxInputTokens": 77,
      "outputCostPerImage": 0.04,
      "mode": "image_generation",
      "provider": "bedrock"
    },
    "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1": {
      "maxTokens": 77,
      "maxInputTokens": 77,
      "outputCostPerImage": 0.08,
      "mode": "image_generation",
      "provider": "bedrock"
    },
    "sagemaker/meta-textgeneration-llama-2-7b": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "sagemaker"
    },
    "sagemaker/meta-textgeneration-llama-2-7b-f": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "sagemaker"
    },
    "sagemaker/meta-textgeneration-llama-2-13b": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "sagemaker"
    },
    "sagemaker/meta-textgeneration-llama-2-13b-f": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "sagemaker"
    },
    "sagemaker/meta-textgeneration-llama-2-70b": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "sagemaker"
    },
    "sagemaker/meta-textgeneration-llama-2-70b-b-f": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "sagemaker"
    },
    "together-ai-up-to-4b": {
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 1e-7,
      "provider": "together_ai"
    },
    "together-ai-4.1b-8b": {
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 2e-7,
      "provider": "together_ai"
    },
    "together-ai-8.1b-21b": {
      "maxTokens": 1000,
      "inputCostPerToken": 3e-7,
      "outputCostPerToken": 3e-7,
      "provider": "together_ai"
    },
    "together-ai-21.1b-41b": {
      "inputCostPerToken": 8e-7,
      "outputCostPerToken": 8e-7,
      "provider": "together_ai"
    },
    "together-ai-41.1b-80b": {
      "inputCostPerToken": 9e-7,
      "outputCostPerToken": 9e-7,
      "provider": "together_ai"
    },
    "together-ai-81.1b-110b": {
      "inputCostPerToken": 0.0000018,
      "outputCostPerToken": 0.0000018,
      "provider": "together_ai"
    },
    "together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "inputCostPerToken": 6e-7,
      "outputCostPerToken": 6e-7,
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "together_ai"
    },
    "together_ai/mistralai/Mistral-7B-Instruct-v0.1": {
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "together_ai"
    },
    "together_ai/togethercomputer/CodeLlama-34b-Instruct": {
      "supportsFunctionCalling": true,
      "supportsParallelFunctionCalling": true,
      "provider": "together_ai"
    },
    "ollama/codegemma": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "ollama"
    },
    "ollama/codegeex4": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "supportsFunctionCalling": false,
      "provider": "ollama"
    },
    "ollama/deepseek-coder-v2-instruct": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "ollama"
    },
    "ollama/deepseek-coder-v2-base": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "supportsFunctionCalling": true,
      "provider": "ollama"
    },
    "ollama/deepseek-coder-v2-lite-instruct": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "ollama"
    },
    "ollama/deepseek-coder-v2-lite-base": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "supportsFunctionCalling": true,
      "provider": "ollama"
    },
    "ollama/internlm2_5-20b-chat": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "ollama"
    },
    "ollama/llama2": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "ollama"
    },
    "ollama/llama2:7b": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "ollama"
    },
    "ollama/llama2:13b": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "ollama"
    },
    "ollama/llama2:70b": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "ollama"
    },
    "ollama/llama2-uncensored": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "ollama"
    },
    "ollama/llama3": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "ollama"
    },
    "ollama/llama3:8b": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "ollama"
    },
    "ollama/llama3:70b": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "ollama"
    },
    "ollama/llama3.1": {
      "maxTokens": 32768,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "provider": "ollama"
    },
    "ollama/mistral-large-instruct-2407": {
      "maxTokens": 65536,
      "maxInputTokens": 65536,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "ollama"
    },
    "ollama/mistral": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "ollama"
    },
    "ollama/mistral-7B-Instruct-v0.1": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "ollama"
    },
    "ollama/mistral-7B-Instruct-v0.2": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 32768,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "ollama"
    },
    "ollama/mixtral-8x7B-Instruct-v0.1": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 32768,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "ollama"
    },
    "ollama/mixtral-8x22B-Instruct-v0.1": {
      "maxTokens": 65536,
      "maxInputTokens": 65536,
      "maxOutputTokens": 65536,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "chat",
      "provider": "ollama"
    },
    "ollama/codellama": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "ollama"
    },
    "ollama/orca-mini": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "ollama"
    },
    "ollama/vicuna": {
      "maxTokens": 2048,
      "maxInputTokens": 2048,
      "maxOutputTokens": 2048,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0,
      "mode": "completion",
      "provider": "ollama"
    },
    "deepinfra/lizpreciatior/lzlv_70b_fp16_hf": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 7e-7,
      "outputCostPerToken": 9e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/Gryphe/MythoMax-L2-13b": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 2.2e-7,
      "outputCostPerToken": 2.2e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/mistralai/Mistral-7B-Instruct-v0.1": {
      "maxTokens": 8191,
      "maxInputTokens": 32768,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 1.3e-7,
      "outputCostPerToken": 1.3e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/meta-llama/Llama-2-70b-chat-hf": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 7e-7,
      "outputCostPerToken": 9e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b": {
      "maxTokens": 8191,
      "maxInputTokens": 32768,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 2.7e-7,
      "outputCostPerToken": 2.7e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/codellama/CodeLlama-34b-Instruct-hf": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 6e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/deepinfra/mixtral": {
      "maxTokens": 4096,
      "maxInputTokens": 32000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 2.7e-7,
      "outputCostPerToken": 2.7e-7,
      "mode": "completion",
      "provider": "deepinfra"
    },
    "deepinfra/Phind/Phind-CodeLlama-34B-v2": {
      "maxTokens": 4096,
      "maxInputTokens": 16384,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 6e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "maxTokens": 8191,
      "maxInputTokens": 32768,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 2.7e-7,
      "outputCostPerToken": 2.7e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/deepinfra/airoboros-70b": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 7e-7,
      "outputCostPerToken": 9e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/01-ai/Yi-34B-Chat": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 6e-7,
      "outputCostPerToken": 6e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/01-ai/Yi-6B-200K": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.3e-7,
      "outputCostPerToken": 1.3e-7,
      "mode": "completion",
      "provider": "deepinfra"
    },
    "deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 7e-7,
      "outputCostPerToken": 9e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/meta-llama/Llama-2-13b-chat-hf": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 2.2e-7,
      "outputCostPerToken": 2.2e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/amazon/MistralLite": {
      "maxTokens": 8191,
      "maxInputTokens": 32768,
      "maxOutputTokens": 8191,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 2e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/meta-llama/Llama-2-7b-chat-hf": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.3e-7,
      "outputCostPerToken": 1.3e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/meta-llama/Meta-Llama-3-8B-Instruct": {
      "maxTokens": 8191,
      "maxInputTokens": 8191,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 8e-8,
      "outputCostPerToken": 8e-8,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/meta-llama/Meta-Llama-3-70B-Instruct": {
      "maxTokens": 8191,
      "maxInputTokens": 8191,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5.9e-7,
      "outputCostPerToken": 7.9e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "deepinfra/01-ai/Yi-34B-200K": {
      "maxTokens": 4096,
      "maxInputTokens": 200000,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 6e-7,
      "outputCostPerToken": 6e-7,
      "mode": "completion",
      "provider": "deepinfra"
    },
    "deepinfra/openchat/openchat_3.5": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.3e-7,
      "outputCostPerToken": 1.3e-7,
      "mode": "chat",
      "provider": "deepinfra"
    },
    "perplexity/codellama-34b-instruct": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 3.5e-7,
      "outputCostPerToken": 0.0000014,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/codellama-70b-instruct": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 7e-7,
      "outputCostPerToken": 0.0000028,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/llama-3.1-70b-instruct": {
      "maxTokens": 131072,
      "maxInputTokens": 131072,
      "maxOutputTokens": 131072,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000001,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/llama-3.1-8b-instruct": {
      "maxTokens": 131072,
      "maxInputTokens": 131072,
      "maxOutputTokens": 131072,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 2e-7,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/llama-3.1-sonar-huge-128k-online": {
      "maxTokens": 127072,
      "maxInputTokens": 127072,
      "maxOutputTokens": 127072,
      "inputCostPerToken": 0.000005,
      "outputCostPerToken": 0.000005,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/llama-3.1-sonar-large-128k-online": {
      "maxTokens": 127072,
      "maxInputTokens": 127072,
      "maxOutputTokens": 127072,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000001,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/llama-3.1-sonar-large-128k-chat": {
      "maxTokens": 131072,
      "maxInputTokens": 131072,
      "maxOutputTokens": 131072,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000001,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/llama-3.1-sonar-small-128k-chat": {
      "maxTokens": 131072,
      "maxInputTokens": 131072,
      "maxOutputTokens": 131072,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 2e-7,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/llama-3.1-sonar-small-128k-online": {
      "maxTokens": 127072,
      "maxInputTokens": 127072,
      "maxOutputTokens": 127072,
      "inputCostPerToken": 2e-7,
      "outputCostPerToken": 2e-7,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/pplx-7b-chat": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 7e-8,
      "outputCostPerToken": 2.8e-7,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/pplx-70b-chat": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 7e-7,
      "outputCostPerToken": 0.0000028,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/pplx-7b-online": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 2.8e-7,
      "inputCostPerRequest": 0.005,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/pplx-70b-online": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0.0000028,
      "inputCostPerRequest": 0.005,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/llama-2-70b-chat": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 7e-7,
      "outputCostPerToken": 0.0000028,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/mistral-7b-instruct": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 7e-8,
      "outputCostPerToken": 2.8e-7,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/mixtral-8x7b-instruct": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 7e-8,
      "outputCostPerToken": 2.8e-7,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/sonar-small-chat": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 7e-8,
      "outputCostPerToken": 2.8e-7,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/sonar-small-online": {
      "maxTokens": 12000,
      "maxInputTokens": 12000,
      "maxOutputTokens": 12000,
      "inputCostPerToken": 0,
      "outputCostPerToken": 2.8e-7,
      "inputCostPerRequest": 0.005,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/sonar-medium-chat": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 6e-7,
      "outputCostPerToken": 0.0000018,
      "mode": "chat",
      "provider": "perplexity"
    },
    "perplexity/sonar-medium-online": {
      "maxTokens": 12000,
      "maxInputTokens": 12000,
      "maxOutputTokens": 12000,
      "inputCostPerToken": 0,
      "outputCostPerToken": 0.0000018,
      "inputCostPerRequest": 0.005,
      "mode": "chat",
      "provider": "perplexity"
    },
    "fireworks_ai/accounts/fireworks/models/firefunction-v2": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 9e-7,
      "outputCostPerToken": 9e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://fireworks.ai/pricing",
      "provider": "fireworks_ai"
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf": {
      "maxTokens": 65536,
      "maxInputTokens": 65536,
      "maxOutputTokens": 65536,
      "inputCostPerToken": 0.0000012,
      "outputCostPerToken": 0.0000012,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://fireworks.ai/pricing",
      "provider": "fireworks_ai"
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 32768,
      "inputCostPerToken": 9e-7,
      "outputCostPerToken": 9e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://fireworks.ai/pricing",
      "provider": "fireworks_ai"
    },
    "fireworks_ai/accounts/fireworks/models/yi-large": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 32768,
      "inputCostPerToken": 0.000003,
      "outputCostPerToken": 0.000003,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://fireworks.ai/pricing",
      "provider": "fireworks_ai"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct": {
      "maxTokens": 65536,
      "maxInputTokens": 65536,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.0000012,
      "outputCostPerToken": 0.0000012,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://fireworks.ai/pricing",
      "provider": "fireworks_ai"
    },
    "anyscale/mistralai/Mistral-7B-Instruct-v0.1": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 1.5e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mistral-7B-Instruct-v0.1",
      "provider": "anyscale"
    },
    "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 1.5e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x7B-Instruct-v0.1",
      "provider": "anyscale"
    },
    "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1": {
      "maxTokens": 65536,
      "maxInputTokens": 65536,
      "maxOutputTokens": 65536,
      "inputCostPerToken": 9e-7,
      "outputCostPerToken": 9e-7,
      "mode": "chat",
      "supportsFunctionCalling": true,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1",
      "provider": "anyscale"
    },
    "anyscale/HuggingFaceH4/zephyr-7b-beta": {
      "maxTokens": 16384,
      "maxInputTokens": 16384,
      "maxOutputTokens": 16384,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 1.5e-7,
      "mode": "chat",
      "provider": "anyscale"
    },
    "anyscale/google/gemma-7b-it": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 1.5e-7,
      "mode": "chat",
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it",
      "provider": "anyscale"
    },
    "anyscale/meta-llama/Llama-2-7b-chat-hf": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 1.5e-7,
      "mode": "chat",
      "provider": "anyscale"
    },
    "anyscale/meta-llama/Llama-2-13b-chat-hf": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 2.5e-7,
      "outputCostPerToken": 2.5e-7,
      "mode": "chat",
      "provider": "anyscale"
    },
    "anyscale/meta-llama/Llama-2-70b-chat-hf": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000001,
      "mode": "chat",
      "provider": "anyscale"
    },
    "anyscale/codellama/CodeLlama-34b-Instruct-hf": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000001,
      "mode": "chat",
      "provider": "anyscale"
    },
    "anyscale/codellama/CodeLlama-70b-Instruct-hf": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000001,
      "mode": "chat",
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf",
      "provider": "anyscale"
    },
    "anyscale/meta-llama/Meta-Llama-3-8B-Instruct": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 1.5e-7,
      "outputCostPerToken": 1.5e-7,
      "mode": "chat",
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-8B-Instruct",
      "provider": "anyscale"
    },
    "anyscale/meta-llama/Meta-Llama-3-70B-Instruct": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.000001,
      "outputCostPerToken": 0.000001,
      "mode": "chat",
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct",
      "provider": "anyscale"
    },
    "cloudflare/@cf/meta/llama-2-7b-chat-fp16": {
      "maxTokens": 3072,
      "maxInputTokens": 3072,
      "maxOutputTokens": 3072,
      "inputCostPerToken": 0.000001923,
      "outputCostPerToken": 0.000001923,
      "mode": "chat",
      "provider": "cloudflare"
    },
    "cloudflare/@cf/meta/llama-2-7b-chat-int8": {
      "maxTokens": 2048,
      "maxInputTokens": 2048,
      "maxOutputTokens": 2048,
      "inputCostPerToken": 0.000001923,
      "outputCostPerToken": 0.000001923,
      "mode": "chat",
      "provider": "cloudflare"
    },
    "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 0.000001923,
      "outputCostPerToken": 0.000001923,
      "mode": "chat",
      "provider": "cloudflare"
    },
    "cloudflare/@hf/thebloke/codellama-7b-instruct-awq": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 0.000001923,
      "outputCostPerToken": 0.000001923,
      "mode": "chat",
      "provider": "cloudflare"
    },
    "voyage/voyage-01": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "voyage"
    },
    "voyage/voyage-lite-01": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "voyage"
    },
    "voyage/voyage-large-2": {
      "maxTokens": 16000,
      "maxInputTokens": 16000,
      "inputCostPerToken": 1.2e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "voyage"
    },
    "voyage/voyage-law-2": {
      "maxTokens": 16000,
      "maxInputTokens": 16000,
      "inputCostPerToken": 1.2e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "voyage"
    },
    "voyage/voyage-code-2": {
      "maxTokens": 16000,
      "maxInputTokens": 16000,
      "inputCostPerToken": 1.2e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "voyage"
    },
    "voyage/voyage-2": {
      "maxTokens": 4000,
      "maxInputTokens": 4000,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "voyage"
    },
    "voyage/voyage-lite-02-instruct": {
      "maxTokens": 4000,
      "maxInputTokens": 4000,
      "inputCostPerToken": 1e-7,
      "outputCostPerToken": 0,
      "mode": "embedding",
      "provider": "voyage"
    },
    "databricks/databricks-meta-llama-3-1-405b-instruct": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 0.000005,
      "inputDbuCostPerToken": 0.000071429,
      "outputCostPerToken": 0.00001500002,
      "outputDbCostPerToken": 0.000214286,
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "provider": "databricks"
    },
    "databricks/databricks-meta-llama-3-1-70b-instruct": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 0.00000100002,
      "inputDbuCostPerToken": 0.000014286,
      "outputCostPerToken": 0.00000299999,
      "outputDbuCostPerToken": 0.000042857,
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "provider": "databricks"
    },
    "databricks/databricks-dbrx-instruct": {
      "maxTokens": 32768,
      "maxInputTokens": 32768,
      "maxOutputTokens": 32768,
      "inputCostPerToken": 7.4998e-7,
      "inputDbuCostPerToken": 0.000010714,
      "outputCostPerToken": 0.00000224901,
      "outputDbuCostPerToken": 0.000032143,
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "provider": "databricks"
    },
    "databricks/databricks-meta-llama-3-70b-instruct": {
      "maxTokens": 128000,
      "maxInputTokens": 128000,
      "maxOutputTokens": 128000,
      "inputCostPerToken": 0.00000100002,
      "inputDbuCostPerToken": 0.000014286,
      "outputCostPerToken": 0.00000299999,
      "outputDbuCostPerToken": 0.000042857,
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "provider": "databricks"
    },
    "databricks/databricks-llama-2-70b-chat": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5.0001e-7,
      "inputDbuCostPerToken": 0.000007143,
      "outputCostPerToken": 0.0000015,
      "outputDbuCostPerToken": 0.000021429,
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "provider": "databricks"
    },
    "databricks/databricks-mixtral-8x7b-instruct": {
      "maxTokens": 4096,
      "maxInputTokens": 4096,
      "maxOutputTokens": 4096,
      "inputCostPerToken": 5.0001e-7,
      "inputDbuCostPerToken": 0.000007143,
      "outputCostPerToken": 9.9902e-7,
      "outputDbuCostPerToken": 0.000014286,
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "provider": "databricks"
    },
    "databricks/databricks-mpt-30b-instruct": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 9.9902e-7,
      "inputDbuCostPerToken": 0.000014286,
      "outputCostPerToken": 9.9902e-7,
      "outputDbuCostPerToken": 0.000014286,
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "provider": "databricks"
    },
    "databricks/databricks-mpt-7b-instruct": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "maxOutputTokens": 8192,
      "inputCostPerToken": 5.0001e-7,
      "inputDbuCostPerToken": 0.000007143,
      "outputCostPerToken": 0,
      "outputDbuCostPerToken": 0,
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "provider": "databricks"
    },
    "databricks/databricks-bge-large-en": {
      "maxTokens": 512,
      "maxInputTokens": 512,
      "outputVectorSize": 1024,
      "inputCostPerToken": 1.0003e-7,
      "inputDbuCostPerToken": 0.000001429,
      "outputCostPerToken": 0,
      "outputDbuCostPerToken": 0,
      "mode": "embedding",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "provider": "databricks"
    },
    "databricks/databricks-gte-large-en": {
      "maxTokens": 8192,
      "maxInputTokens": 8192,
      "outputVectorSize": 1024,
      "inputCostPerToken": 1.2999e-7,
      "inputDbuCostPerToken": 0.000001857,
      "outputCostPerToken": 0,
      "outputDbuCostPerToken": 0,
      "mode": "embedding",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
      "metadata": {
        "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
      },
      "provider": "databricks"
    }
  },
  "genericModels": {
    "tts-1": {
      "providers": [
        "azure"
      ]
    },
    "tts-1-hd": {
      "providers": [
        "azure"
      ]
    },
    "whisper-1": {
      "providers": [
        "azure"
      ]
    },
    "gpt-4o": {
      "providers": [
        "azure",
        "openrouter/openai"
      ]
    },
    "gpt-4o-2024-08-06": {
      "providers": [
        "azure",
        "azure/global-standard"
      ]
    },
    "gpt-4o-mini": {
      "providers": [
        "azure/global-standard",
        "azure"
      ]
    },
    "gpt-4-turbo-2024-04-09": {
      "providers": [
        "azure"
      ]
    },
    "gpt-4-0125-preview": {
      "providers": [
        "azure"
      ]
    },
    "gpt-4-1106-preview": {
      "providers": [
        "azure"
      ]
    },
    "gpt-4-0613": {
      "providers": [
        "azure"
      ]
    },
    "gpt-4-32k-0613": {
      "providers": [
        "azure"
      ]
    },
    "gpt-4-32k": {
      "providers": [
        "azure"
      ]
    },
    "gpt-4": {
      "providers": [
        "azure",
        "openrouter/openai"
      ]
    },
    "gpt-4-turbo": {
      "providers": [
        "azure"
      ]
    },
    "gpt-4-turbo-vision-preview": {
      "providers": [
        "azure"
      ]
    },
    "gpt-35-turbo-16k-0613": {
      "providers": [
        "azure"
      ]
    },
    "gpt-35-turbo-1106": {
      "providers": [
        "azure"
      ]
    },
    "gpt-35-turbo-0125": {
      "providers": [
        "azure"
      ]
    },
    "gpt-35-turbo-16k": {
      "providers": [
        "azure"
      ]
    },
    "gpt-35-turbo": {
      "providers": [
        "azure"
      ]
    },
    "gpt-3.5-turbo-instruct-0914": {
      "providers": [
        "azure"
      ]
    },
    "gpt-35-turbo-instruct": {
      "providers": [
        "azure"
      ]
    },
    "mistral-large-latest": {
      "providers": [
        "azure",
        "mistral"
      ]
    },
    "mistral-large-2402": {
      "providers": [
        "azure",
        "mistral"
      ]
    },
    "command-r-plus": {
      "providers": [
        "azure",
        "openrouter/cohere"
      ]
    },
    "ada": {
      "providers": [
        "azure"
      ]
    },
    "text-embedding-ada-002": {
      "providers": [
        "azure"
      ]
    },
    "text-embedding-3-large": {
      "providers": [
        "azure"
      ]
    },
    "text-embedding-3-small": {
      "providers": [
        "azure"
      ]
    },
    "jamba-instruct": {
      "providers": [
        "azure_ai"
      ]
    },
    "mistral-large": {
      "providers": [
        "azure_ai",
        "openrouter/mistralai"
      ]
    },
    "mistral-small": {
      "providers": [
        "azure_ai",
        "mistral"
      ]
    },
    "Meta-Llama-3-70B-Instruct": {
      "providers": [
        "azure_ai",
        "deepinfra/meta-llama",
        "anyscale/meta-llama"
      ]
    },
    "Meta-Llama-31-8B-Instruct": {
      "providers": [
        "azure_ai"
      ]
    },
    "Meta-Llama-31-70B-Instruct": {
      "providers": [
        "azure_ai"
      ]
    },
    "Meta-Llama-31-405B-Instruct": {
      "providers": [
        "azure_ai"
      ]
    },
    "mistral-tiny": {
      "providers": [
        "mistral"
      ]
    },
    "mistral-small-latest": {
      "providers": [
        "mistral"
      ]
    },
    "mistral-medium": {
      "providers": [
        "mistral"
      ]
    },
    "mistral-medium-latest": {
      "providers": [
        "mistral"
      ]
    },
    "mistral-medium-2312": {
      "providers": [
        "mistral"
      ]
    },
    "mistral-large-2407": {
      "providers": [
        "mistral"
      ]
    },
    "open-mistral-7b": {
      "providers": [
        "mistral"
      ]
    },
    "open-mixtral-8x7b": {
      "providers": [
        "mistral"
      ]
    },
    "open-mixtral-8x22b": {
      "providers": [
        "mistral"
      ]
    },
    "codestral-latest": {
      "providers": [
        "mistral",
        "codestral",
        "text-completion-codestral"
      ]
    },
    "codestral-2405": {
      "providers": [
        "mistral",
        "codestral",
        "text-completion-codestral"
      ]
    },
    "open-mistral-nemo": {
      "providers": [
        "mistral"
      ]
    },
    "open-mistral-nemo-2407": {
      "providers": [
        "mistral"
      ]
    },
    "open-codestral-mamba": {
      "providers": [
        "mistral"
      ]
    },
    "codestral-mamba-latest": {
      "providers": [
        "mistral"
      ]
    },
    "mistral-embed": {
      "providers": [
        "mistral"
      ]
    },
    "llama2-70b-4096": {
      "providers": [
        "groq"
      ]
    },
    "llama3-8b-8192": {
      "providers": [
        "groq"
      ]
    },
    "llama3-70b-8192": {
      "providers": [
        "groq"
      ]
    },
    "llama-3.1-8b-instant": {
      "providers": [
        "groq"
      ]
    },
    "llama-3.1-70b-versatile": {
      "providers": [
        "groq"
      ]
    },
    "llama-3.1-405b-reasoning": {
      "providers": [
        "groq"
      ]
    },
    "mixtral-8x7b-32768": {
      "providers": [
        "groq"
      ]
    },
    "gemma-7b-it": {
      "providers": [
        "groq",
        "anyscale/google"
      ]
    },
    "llama3-groq-70b-8192-tool-use-preview": {
      "providers": [
        "groq"
      ]
    },
    "llama3-groq-8b-8192-tool-use-preview": {
      "providers": [
        "groq"
      ]
    },
    "llama3.1-8b": {
      "providers": [
        "cerebras"
      ]
    },
    "llama3.1-70b": {
      "providers": [
        "cerebras"
      ]
    },
    "mixtral-8x7b-instruct-v0-1": {
      "providers": [
        "friendliai"
      ]
    },
    "meta-llama-3-8b-instruct": {
      "providers": [
        "friendliai"
      ]
    },
    "meta-llama-3-70b-instruct": {
      "providers": [
        "friendliai"
      ]
    },
    "claude-3-sonnet@20240229": {
      "providers": [
        "vertex_ai"
      ]
    },
    "claude-3-5-sonnet@20240620": {
      "providers": [
        "vertex_ai"
      ]
    },
    "claude-3-haiku@20240307": {
      "providers": [
        "vertex_ai"
      ]
    },
    "claude-3-opus@20240229": {
      "providers": [
        "vertex_ai"
      ]
    },
    "llama3-405b-instruct-maas": {
      "providers": [
        "vertex_ai/meta"
      ]
    },
    "mistral-large@latest": {
      "providers": [
        "vertex_ai"
      ]
    },
    "mistral-large@2407": {
      "providers": [
        "vertex_ai"
      ]
    },
    "mistral-nemo@latest": {
      "providers": [
        "vertex_ai"
      ]
    },
    "jamba-1.5-mini@001": {
      "providers": [
        "vertex_ai"
      ]
    },
    "jamba-1.5-large@001": {
      "providers": [
        "vertex_ai"
      ]
    },
    "jamba-1.5": {
      "providers": [
        "vertex_ai"
      ]
    },
    "jamba-1.5-mini": {
      "providers": [
        "vertex_ai"
      ]
    },
    "jamba-1.5-large": {
      "providers": [
        "vertex_ai"
      ]
    },
    "mistral-nemo@2407": {
      "providers": [
        "vertex_ai"
      ]
    },
    "codestral@latest": {
      "providers": [
        "vertex_ai"
      ]
    },
    "codestral@2405": {
      "providers": [
        "vertex_ai"
      ]
    },
    "chat-bison": {
      "providers": [
        "palm"
      ]
    },
    "chat-bison-001": {
      "providers": [
        "palm"
      ]
    },
    "text-bison": {
      "providers": [
        "palm"
      ]
    },
    "text-bison-001": {
      "providers": [
        "palm"
      ]
    },
    "text-bison-safety-off": {
      "providers": [
        "palm"
      ]
    },
    "text-bison-safety-recitation-off": {
      "providers": [
        "palm"
      ]
    },
    "gemini-1.5-flash-001": {
      "providers": [
        "gemini"
      ]
    },
    "gemini-1.5-flash": {
      "providers": [
        "gemini"
      ]
    },
    "gemini-1.5-flash-latest": {
      "providers": [
        "gemini"
      ]
    },
    "gemini-1.5-flash-exp-0827": {
      "providers": [
        "gemini"
      ]
    },
    "gemini-1.5-flash-8b-exp-0827": {
      "providers": [
        "gemini"
      ]
    },
    "gemini-pro": {
      "providers": [
        "gemini"
      ]
    },
    "gemini-1.5-pro": {
      "providers": [
        "gemini"
      ]
    },
    "gemini-1.5-pro-exp-0801": {
      "providers": [
        "gemini"
      ]
    },
    "gemini-1.5-pro-exp-0827": {
      "providers": [
        "gemini"
      ]
    },
    "gemini-1.5-pro-latest": {
      "providers": [
        "gemini"
      ]
    },
    "gemini-pro-vision": {
      "providers": [
        "gemini",
        "openrouter/google"
      ]
    },
    "gemini-gemma-2-27b-it": {
      "providers": [
        "gemini"
      ]
    },
    "gemini-gemma-2-9b-it": {
      "providers": [
        "gemini"
      ]
    },
    "llama-2-13b": {
      "providers": [
        "replicate/meta"
      ]
    },
    "llama-2-13b-chat": {
      "providers": [
        "replicate/meta",
        "openrouter/meta-llama"
      ]
    },
    "llama-2-70b": {
      "providers": [
        "replicate/meta"
      ]
    },
    "llama-2-70b-chat": {
      "providers": [
        "replicate/meta",
        "openrouter/meta-llama",
        "perplexity"
      ]
    },
    "llama-2-7b": {
      "providers": [
        "replicate/meta"
      ]
    },
    "llama-2-7b-chat": {
      "providers": [
        "replicate/meta"
      ]
    },
    "llama-3-70b": {
      "providers": [
        "replicate/meta"
      ]
    },
    "llama-3-70b-instruct": {
      "providers": [
        "replicate/meta",
        "openrouter/meta-llama"
      ]
    },
    "llama-3-8b": {
      "providers": [
        "replicate/meta"
      ]
    },
    "llama-3-8b-instruct": {
      "providers": [
        "replicate/meta"
      ]
    },
    "mistral-7b-v0.1": {
      "providers": [
        "replicate/mistralai"
      ]
    },
    "mistral-7b-instruct-v0.2": {
      "providers": [
        "replicate/mistralai"
      ]
    },
    "mixtral-8x7b-instruct-v0.1": {
      "providers": [
        "replicate/mistralai"
      ]
    },
    "deepseek-coder": {
      "providers": [
        "openrouter/deepseek"
      ]
    },
    "wizardlm-2-8x22b:nitro": {
      "providers": [
        "openrouter/microsoft"
      ]
    },
    "gemini-pro-1.5": {
      "providers": [
        "openrouter/google"
      ]
    },
    "mixtral-8x22b-instruct": {
      "providers": [
        "openrouter/mistralai"
      ]
    },
    "dbrx-instruct": {
      "providers": [
        "openrouter/databricks"
      ]
    },
    "claude-3-haiku": {
      "providers": [
        "openrouter/anthropic"
      ]
    },
    "claude-3-haiku-20240307": {
      "providers": [
        "openrouter/anthropic"
      ]
    },
    "claude-3.5-sonnet": {
      "providers": [
        "openrouter/anthropic"
      ]
    },
    "claude-3.5-sonnet:beta": {
      "providers": [
        "openrouter/anthropic"
      ]
    },
    "claude-3-sonnet": {
      "providers": [
        "openrouter/anthropic"
      ]
    },
    "dolphin-mixtral-8x7b": {
      "providers": [
        "openrouter/cognitivecomputations"
      ]
    },
    "firellava-13b": {
      "providers": [
        "openrouter/fireworks"
      ]
    },
    "llama-3-8b-instruct:free": {
      "providers": [
        "openrouter/meta-llama"
      ]
    },
    "llama-3-8b-instruct:extended": {
      "providers": [
        "openrouter/meta-llama"
      ]
    },
    "llama-3-70b-instruct:nitro": {
      "providers": [
        "openrouter/meta-llama"
      ]
    },
    "o1-mini": {
      "providers": [
        "openrouter/openai"
      ]
    },
    "o1-mini-2024-09-12": {
      "providers": [
        "openrouter/openai"
      ]
    },
    "o1-preview": {
      "providers": [
        "openrouter/openai"
      ]
    },
    "o1-preview-2024-09-12": {
      "providers": [
        "openrouter/openai"
      ]
    },
    "gpt-4o-2024-05-13": {
      "providers": [
        "openrouter/openai"
      ]
    },
    "gpt-4-vision-preview": {
      "providers": [
        "openrouter/openai"
      ]
    },
    "gpt-3.5-turbo": {
      "providers": [
        "openrouter/openai"
      ]
    },
    "gpt-3.5-turbo-16k": {
      "providers": [
        "openrouter/openai"
      ]
    },
    "claude-instant-v1": {
      "providers": [
        "openrouter/anthropic"
      ]
    },
    "claude-2": {
      "providers": [
        "openrouter/anthropic"
      ]
    },
    "claude-3-opus": {
      "providers": [
        "openrouter/anthropic"
      ]
    },
    "palm-2-chat-bison": {
      "providers": [
        "openrouter/google"
      ]
    },
    "palm-2-codechat-bison": {
      "providers": [
        "openrouter/google"
      ]
    },
    "codellama-34b-instruct": {
      "providers": [
        "openrouter/meta-llama",
        "perplexity"
      ]
    },
    "nous-hermes-llama2-13b": {
      "providers": [
        "openrouter/nousresearch"
      ]
    },
    "weaver": {
      "providers": [
        "openrouter/mancer"
      ]
    },
    "mythomax-l2-13b": {
      "providers": [
        "openrouter/gryphe"
      ]
    },
    "airoboros-l2-70b-2.1": {
      "providers": [
        "openrouter/jondurbin"
      ]
    },
    "remm-slerp-l2-13b": {
      "providers": [
        "openrouter/undi95"
      ]
    },
    "mythalion-13b": {
      "providers": [
        "openrouter/pygmalionai"
      ]
    },
    "mistral-7b-instruct": {
      "providers": [
        "openrouter/mistralai",
        "perplexity"
      ]
    },
    "mistral-7b-instruct:free": {
      "providers": [
        "openrouter/mistralai"
      ]
    },
    "mistral.mixtral-8x7b-instruct-v0:1": {
      "providers": [
        "bedrock/us-west-2",
        "bedrock/us-east-1",
        "bedrock/eu-west-3"
      ]
    },
    "mistral.mistral-7b-instruct-v0:2": {
      "providers": [
        "bedrock/us-west-2",
        "bedrock/us-east-1",
        "bedrock/eu-west-3"
      ]
    },
    "mistral.mistral-large-2402-v1:0": {
      "providers": [
        "bedrock/us-east-1",
        "bedrock/us-west-2",
        "bedrock/eu-west-3"
      ]
    },
    "anthropic.claude-v1": {
      "providers": [
        "bedrock/us-east-1",
        "bedrock/us-west-2",
        "bedrock/ap-northeast-1",
        "bedrock/ap-northeast-1/1-month-commitment",
        "bedrock/ap-northeast-1/6-month-commitment",
        "bedrock/eu-central-1",
        "bedrock/eu-central-1/1-month-commitment",
        "bedrock/eu-central-1/6-month-commitment",
        "bedrock/us-east-1/1-month-commitment",
        "bedrock/us-east-1/6-month-commitment",
        "bedrock/us-west-2/1-month-commitment",
        "bedrock/us-west-2/6-month-commitment"
      ]
    },
    "anthropic.claude-v2": {
      "providers": [
        "bedrock/us-east-1",
        "bedrock/us-west-2",
        "bedrock/ap-northeast-1",
        "bedrock/ap-northeast-1/1-month-commitment",
        "bedrock/ap-northeast-1/6-month-commitment",
        "bedrock/eu-central-1",
        "bedrock/eu-central-1/1-month-commitment",
        "bedrock/eu-central-1/6-month-commitment",
        "bedrock/us-east-1/1-month-commitment",
        "bedrock/us-east-1/6-month-commitment",
        "bedrock/us-west-2/1-month-commitment",
        "bedrock/us-west-2/6-month-commitment"
      ]
    },
    "anthropic.claude-v2:1": {
      "providers": [
        "bedrock/us-east-1",
        "bedrock/us-west-2",
        "bedrock/ap-northeast-1",
        "bedrock/ap-northeast-1/1-month-commitment",
        "bedrock/ap-northeast-1/6-month-commitment",
        "bedrock/eu-central-1",
        "bedrock/eu-central-1/1-month-commitment",
        "bedrock/eu-central-1/6-month-commitment",
        "bedrock/us-east-1/1-month-commitment",
        "bedrock/us-east-1/6-month-commitment",
        "bedrock/us-west-2/1-month-commitment",
        "bedrock/us-west-2/6-month-commitment"
      ]
    },
    "anthropic.claude-instant-v1": {
      "providers": [
        "bedrock/us-east-1",
        "bedrock/us-east-1/1-month-commitment",
        "bedrock/us-east-1/6-month-commitment",
        "bedrock/us-west-2/1-month-commitment",
        "bedrock/us-west-2/6-month-commitment",
        "bedrock/us-west-2",
        "bedrock/ap-northeast-1",
        "bedrock/ap-northeast-1/1-month-commitment",
        "bedrock/ap-northeast-1/6-month-commitment",
        "bedrock/eu-central-1",
        "bedrock/eu-central-1/1-month-commitment",
        "bedrock/eu-central-1/6-month-commitment"
      ]
    },
    "cohere.command-text-v14": {
      "providers": [
        "bedrock/*/1-month-commitment",
        "bedrock/*/6-month-commitment"
      ]
    },
    "cohere.command-light-text-v14": {
      "providers": [
        "bedrock/*/1-month-commitment",
        "bedrock/*/6-month-commitment"
      ]
    },
    "meta.llama3-8b-instruct-v1:0": {
      "providers": [
        "bedrock/us-east-1",
        "bedrock/us-west-1",
        "bedrock/ap-south-1",
        "bedrock/ca-central-1",
        "bedrock/eu-west-1",
        "bedrock/eu-west-2",
        "bedrock/sa-east-1"
      ]
    },
    "meta.llama3-70b-instruct-v1:0": {
      "providers": [
        "bedrock/us-east-1",
        "bedrock/us-west-1",
        "bedrock/ap-south-1",
        "bedrock/ca-central-1",
        "bedrock/eu-west-1",
        "bedrock/eu-west-2",
        "bedrock/sa-east-1"
      ]
    },
    "meta-textgeneration-llama-2-7b": {
      "providers": [
        "sagemaker"
      ]
    },
    "meta-textgeneration-llama-2-7b-f": {
      "providers": [
        "sagemaker"
      ]
    },
    "meta-textgeneration-llama-2-13b": {
      "providers": [
        "sagemaker"
      ]
    },
    "meta-textgeneration-llama-2-13b-f": {
      "providers": [
        "sagemaker"
      ]
    },
    "meta-textgeneration-llama-2-70b": {
      "providers": [
        "sagemaker"
      ]
    },
    "meta-textgeneration-llama-2-70b-b-f": {
      "providers": [
        "sagemaker"
      ]
    },
    "Mixtral-8x7B-Instruct-v0.1": {
      "providers": [
        "together_ai/mistralai",
        "deepinfra/mistralai",
        "anyscale/mistralai"
      ]
    },
    "Mistral-7B-Instruct-v0.1": {
      "providers": [
        "together_ai/mistralai",
        "deepinfra/mistralai",
        "anyscale/mistralai"
      ]
    },
    "CodeLlama-34b-Instruct": {
      "providers": [
        "together_ai/togethercomputer"
      ]
    },
    "codegemma": {
      "providers": [
        "ollama"
      ]
    },
    "codegeex4": {
      "providers": [
        "ollama"
      ]
    },
    "deepseek-coder-v2-instruct": {
      "providers": [
        "ollama",
        "fireworks_ai/accounts/fireworks/models"
      ]
    },
    "deepseek-coder-v2-base": {
      "providers": [
        "ollama"
      ]
    },
    "deepseek-coder-v2-lite-instruct": {
      "providers": [
        "ollama"
      ]
    },
    "deepseek-coder-v2-lite-base": {
      "providers": [
        "ollama"
      ]
    },
    "internlm2_5-20b-chat": {
      "providers": [
        "ollama"
      ]
    },
    "llama2": {
      "providers": [
        "ollama"
      ]
    },
    "llama2:7b": {
      "providers": [
        "ollama"
      ]
    },
    "llama2:13b": {
      "providers": [
        "ollama"
      ]
    },
    "llama2:70b": {
      "providers": [
        "ollama"
      ]
    },
    "llama2-uncensored": {
      "providers": [
        "ollama"
      ]
    },
    "llama3": {
      "providers": [
        "ollama"
      ]
    },
    "llama3:8b": {
      "providers": [
        "ollama"
      ]
    },
    "llama3:70b": {
      "providers": [
        "ollama"
      ]
    },
    "llama3.1": {
      "providers": [
        "ollama"
      ]
    },
    "mistral-large-instruct-2407": {
      "providers": [
        "ollama"
      ]
    },
    "mistral": {
      "providers": [
        "ollama"
      ]
    },
    "mistral-7B-Instruct-v0.1": {
      "providers": [
        "ollama"
      ]
    },
    "mistral-7B-Instruct-v0.2": {
      "providers": [
        "ollama"
      ]
    },
    "mixtral-8x7B-Instruct-v0.1": {
      "providers": [
        "ollama"
      ]
    },
    "mixtral-8x22B-Instruct-v0.1": {
      "providers": [
        "ollama"
      ]
    },
    "codellama": {
      "providers": [
        "ollama"
      ]
    },
    "orca-mini": {
      "providers": [
        "ollama"
      ]
    },
    "vicuna": {
      "providers": [
        "ollama"
      ]
    },
    "lzlv_70b_fp16_hf": {
      "providers": [
        "deepinfra/lizpreciatior"
      ]
    },
    "MythoMax-L2-13b": {
      "providers": [
        "deepinfra/Gryphe"
      ]
    },
    "Llama-2-70b-chat-hf": {
      "providers": [
        "deepinfra/meta-llama",
        "anyscale/meta-llama"
      ]
    },
    "dolphin-2.6-mixtral-8x7b": {
      "providers": [
        "deepinfra/cognitivecomputations"
      ]
    },
    "CodeLlama-34b-Instruct-hf": {
      "providers": [
        "deepinfra/codellama",
        "anyscale/codellama"
      ]
    },
    "mixtral": {
      "providers": [
        "deepinfra/deepinfra"
      ]
    },
    "Phind-CodeLlama-34B-v2": {
      "providers": [
        "deepinfra/Phind"
      ]
    },
    "airoboros-70b": {
      "providers": [
        "deepinfra/deepinfra"
      ]
    },
    "Yi-34B-Chat": {
      "providers": [
        "deepinfra/01-ai"
      ]
    },
    "Yi-6B-200K": {
      "providers": [
        "deepinfra/01-ai"
      ]
    },
    "airoboros-l2-70b-gpt4-1.4.1": {
      "providers": [
        "deepinfra/jondurbin"
      ]
    },
    "Llama-2-13b-chat-hf": {
      "providers": [
        "deepinfra/meta-llama",
        "anyscale/meta-llama"
      ]
    },
    "MistralLite": {
      "providers": [
        "deepinfra/amazon"
      ]
    },
    "Llama-2-7b-chat-hf": {
      "providers": [
        "deepinfra/meta-llama",
        "anyscale/meta-llama"
      ]
    },
    "Meta-Llama-3-8B-Instruct": {
      "providers": [
        "deepinfra/meta-llama",
        "anyscale/meta-llama"
      ]
    },
    "Yi-34B-200K": {
      "providers": [
        "deepinfra/01-ai"
      ]
    },
    "openchat_3.5": {
      "providers": [
        "deepinfra/openchat"
      ]
    },
    "codellama-70b-instruct": {
      "providers": [
        "perplexity"
      ]
    },
    "llama-3.1-70b-instruct": {
      "providers": [
        "perplexity"
      ]
    },
    "llama-3.1-8b-instruct": {
      "providers": [
        "perplexity"
      ]
    },
    "llama-3.1-sonar-huge-128k-online": {
      "providers": [
        "perplexity"
      ]
    },
    "llama-3.1-sonar-large-128k-online": {
      "providers": [
        "perplexity"
      ]
    },
    "llama-3.1-sonar-large-128k-chat": {
      "providers": [
        "perplexity"
      ]
    },
    "llama-3.1-sonar-small-128k-chat": {
      "providers": [
        "perplexity"
      ]
    },
    "llama-3.1-sonar-small-128k-online": {
      "providers": [
        "perplexity"
      ]
    },
    "pplx-7b-chat": {
      "providers": [
        "perplexity"
      ]
    },
    "pplx-70b-chat": {
      "providers": [
        "perplexity"
      ]
    },
    "pplx-7b-online": {
      "providers": [
        "perplexity"
      ]
    },
    "pplx-70b-online": {
      "providers": [
        "perplexity"
      ]
    },
    "mixtral-8x7b-instruct": {
      "providers": [
        "perplexity"
      ]
    },
    "sonar-small-chat": {
      "providers": [
        "perplexity"
      ]
    },
    "sonar-small-online": {
      "providers": [
        "perplexity"
      ]
    },
    "sonar-medium-chat": {
      "providers": [
        "perplexity"
      ]
    },
    "sonar-medium-online": {
      "providers": [
        "perplexity"
      ]
    },
    "firefunction-v2": {
      "providers": [
        "fireworks_ai/accounts/fireworks/models"
      ]
    },
    "mixtral-8x22b-instruct-hf": {
      "providers": [
        "fireworks_ai/accounts/fireworks/models"
      ]
    },
    "qwen2-72b-instruct": {
      "providers": [
        "fireworks_ai/accounts/fireworks/models"
      ]
    },
    "yi-large": {
      "providers": [
        "fireworks_ai/accounts/fireworks/models"
      ]
    },
    "Mixtral-8x22B-Instruct-v0.1": {
      "providers": [
        "anyscale/mistralai"
      ]
    },
    "zephyr-7b-beta": {
      "providers": [
        "anyscale/HuggingFaceH4"
      ]
    },
    "CodeLlama-70b-Instruct-hf": {
      "providers": [
        "anyscale/codellama"
      ]
    },
    "llama-2-7b-chat-fp16": {
      "providers": [
        "cloudflare/@cf/meta"
      ]
    },
    "llama-2-7b-chat-int8": {
      "providers": [
        "cloudflare/@cf/meta"
      ]
    },
    "mistral-7b-instruct-v0.1": {
      "providers": [
        "cloudflare/@cf/mistral"
      ]
    },
    "codellama-7b-instruct-awq": {
      "providers": [
        "cloudflare/@hf/thebloke"
      ]
    },
    "voyage-01": {
      "providers": [
        "voyage"
      ]
    },
    "voyage-lite-01": {
      "providers": [
        "voyage"
      ]
    },
    "voyage-large-2": {
      "providers": [
        "voyage"
      ]
    },
    "voyage-law-2": {
      "providers": [
        "voyage"
      ]
    },
    "voyage-code-2": {
      "providers": [
        "voyage"
      ]
    },
    "voyage-2": {
      "providers": [
        "voyage"
      ]
    },
    "voyage-lite-02-instruct": {
      "providers": [
        "voyage"
      ]
    },
    "databricks-meta-llama-3-1-405b-instruct": {
      "providers": [
        "databricks"
      ]
    },
    "databricks-meta-llama-3-1-70b-instruct": {
      "providers": [
        "databricks"
      ]
    },
    "databricks-dbrx-instruct": {
      "providers": [
        "databricks"
      ]
    },
    "databricks-meta-llama-3-70b-instruct": {
      "providers": [
        "databricks"
      ]
    },
    "databricks-llama-2-70b-chat": {
      "providers": [
        "databricks"
      ]
    },
    "databricks-mixtral-8x7b-instruct": {
      "providers": [
        "databricks"
      ]
    },
    "databricks-mpt-30b-instruct": {
      "providers": [
        "databricks"
      ]
    },
    "databricks-mpt-7b-instruct": {
      "providers": [
        "databricks"
      ]
    },
    "databricks-bge-large-en": {
      "providers": [
        "databricks"
      ]
    },
    "databricks-gte-large-en": {
      "providers": [
        "databricks"
      ]
    }
  },
  "imageModels": {
    "dall-e-2": {
      "mode": "image_generation",
      "inputCostPerPixel": 2.4414e-7,
      "outputCostPerPixel": 0,
      "sizes": [
        "256-x-256",
        "512-x-512",
        "1024-x-1024"
      ],
      "qualities": [
        "standard"
      ],
      "providers": [
        "openai",
        "azure"
      ]
    },
    "dall-e-3": {
      "mode": "image_generation",
      "inputCostPerPixel": 6.539e-8,
      "outputCostPerPixel": 0,
      "sizes": [
        "1024-x-1792",
        "1792-x-1024",
        "1024-x-1024"
      ],
      "qualities": [
        "hd",
        "standard"
      ],
      "providers": [
        "openai",
        "azure"
      ]
    },
    "imagegeneration@006": {
      "costPerImage": 0.02,
      "mode": "image_generation",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "sizes": [],
      "qualities": [
        "vertex_ai"
      ],
      "providers": [
        "vertex_ai-image-models"
      ]
    },
    "imagen-3.0-generate-001": {
      "costPerImage": 0.04,
      "mode": "image_generation",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "sizes": [],
      "qualities": [
        "vertex_ai"
      ],
      "providers": [
        "vertex_ai-image-models"
      ]
    },
    "imagen-3.0-fast-generate-001": {
      "costPerImage": 0.02,
      "mode": "image_generation",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
      "sizes": [],
      "qualities": [
        "vertex_ai"
      ],
      "providers": [
        "vertex_ai-image-models"
      ]
    },
    "stability.stable-diffusion-xl-v0": {
      "maxTokens": 77,
      "maxInputTokens": 77,
      "outputCostPerImage": 0.018,
      "mode": "image_generation",
      "sizes": [
        "512-x-512",
        "max-x-max"
      ],
      "qualities": [
        "50-steps",
        "max-steps"
      ],
      "providers": [
        "bedrock"
      ]
    },
    "stability.stable-diffusion-xl-v1": {
      "maxTokens": 77,
      "maxInputTokens": 77,
      "outputCostPerImage": 0.04,
      "mode": "image_generation",
      "sizes": [
        "1024-x-1024"
      ],
      "qualities": [
        "50-steps",
        "max-steps"
      ],
      "providers": [
        "bedrock"
      ]
    }
  }
}